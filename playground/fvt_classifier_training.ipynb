{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3b-jet events:  275508\n",
      "4b-jet events:  382108\n",
      "HH4b-jet events:  28656\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "seed_ = 42\n",
    "\n",
    "dim = 16\n",
    "directory = pathlib.Path(\"../events/MG3\")\n",
    "\n",
    "df_3b = pd.read_hdf(directory / \"dataframes\" / \"symmetrized_bbbj.h5\")\n",
    "df_bg4b = pd.read_hdf(directory / \"dataframes\" / \"symmetrized_bbbb_large.h5\")\n",
    "df_hh4b = pd.read_hdf(directory / \"dataframes\" / \"symmetrized_HH4b.h5\")\n",
    "\n",
    "df_3b[\"signal\"] = False\n",
    "df_bg4b[\"signal\"] = False\n",
    "df_hh4b[\"signal\"] = True\n",
    "\n",
    "print(\"3b-jet events: \", len(df_3b))\n",
    "print(\"4b-jet events: \", len(df_bg4b))\n",
    "print(\"HH4b-jet events: \", len(df_hh4b))\n",
    "\n",
    "# shuffle the data\n",
    "df_3b = df_3b.sample(frac=1, random_state=seed_).reset_index(drop=True)\n",
    "df_bg4b = df_bg4b.sample(frac=1, random_state=seed_).reset_index(drop=True)\n",
    "df_hh4b = df_hh4b.sample(frac=1, random_state=seed_).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4b ratio:  0.4989991\n",
      "Signal ratio:  0.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "/home/soheuny/miniconda3/envs/coffea_torch/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:653: Checkpoint directory /home/soheuny/HH4bsim/playground/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type       | Params\n",
      "----------------------------------------\n",
      "0 | encoder  | FvTEncoder | 920   \n",
      "1 | select_q | conv1d     | 8     \n",
      "2 | out      | conv1d     | 16    \n",
      "----------------------------------------\n",
      "895       Trainable params\n",
      "49        Non-trainable params\n",
      "944       Total params\n",
      "0.004     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 162/162 [00:03<00:00, 49.61it/s, v_num=0, val_loss=0.692, train_loss=0.691]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 162/162 [00:03<00:00, 49.52it/s, v_num=0, val_loss=0.692, train_loss=0.691]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/soheuny/miniconda3/envs/coffea_torch/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:653: Checkpoint directory /home/soheuny/HH4bsim/playground/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type       | Params\n",
      "----------------------------------------\n",
      "0 | encoder  | FvTEncoder | 920   \n",
      "1 | select_q | conv1d     | 8     \n",
      "2 | out      | conv1d     | 16    \n",
      "----------------------------------------\n",
      "895       Trainable params\n",
      "49        Non-trainable params\n",
      "944       Total params\n",
      "0.004     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4b ratio:  0.49900398\n",
      "Signal ratio:  0.04\n",
      "Epoch 29: 100%|██████████| 162/162 [00:02<00:00, 63.50it/s, v_num=0, val_loss=0.692, train_loss=0.691]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 162/162 [00:02<00:00, 63.39it/s, v_num=0, val_loss=0.692, train_loss=0.691]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4b ratio:  0.4990017\n",
      "Signal ratio:  0.060000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/soheuny/miniconda3/envs/coffea_torch/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:653: Checkpoint directory /home/soheuny/HH4bsim/playground/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type       | Params\n",
      "----------------------------------------\n",
      "0 | encoder  | FvTEncoder | 920   \n",
      "1 | select_q | conv1d     | 8     \n",
      "2 | out      | conv1d     | 16    \n",
      "----------------------------------------\n",
      "895       Trainable params\n",
      "49        Non-trainable params\n",
      "944       Total params\n",
      "0.004     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 162/162 [00:02<00:00, 60.98it/s, v_num=0, val_loss=0.692, train_loss=0.691]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 162/162 [00:02<00:00, 60.27it/s, v_num=0, val_loss=0.692, train_loss=0.691]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4b ratio:  0.4989975\n",
      "Signal ratio:  0.07000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/soheuny/miniconda3/envs/coffea_torch/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:653: Checkpoint directory /home/soheuny/HH4bsim/playground/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type       | Params\n",
      "----------------------------------------\n",
      "0 | encoder  | FvTEncoder | 920   \n",
      "1 | select_q | conv1d     | 8     \n",
      "2 | out      | conv1d     | 16    \n",
      "----------------------------------------\n",
      "895       Trainable params\n",
      "49        Non-trainable params\n",
      "944       Total params\n",
      "0.004     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 162/162 [00:03<00:00, 51.39it/s, v_num=0, val_loss=0.691, train_loss=0.691]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 162/162 [00:03<00:00, 51.30it/s, v_num=0, val_loss=0.691, train_loss=0.691]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/soheuny/miniconda3/envs/coffea_torch/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:653: Checkpoint directory /home/soheuny/HH4bsim/playground/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type       | Params\n",
      "----------------------------------------\n",
      "0 | encoder  | FvTEncoder | 920   \n",
      "1 | select_q | conv1d     | 8     \n",
      "2 | out      | conv1d     | 16    \n",
      "----------------------------------------\n",
      "895       Trainable params\n",
      "49        Non-trainable params\n",
      "944       Total params\n",
      "0.004     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4b ratio:  0.49899468\n",
      "Signal ratio:  0.07999999\n",
      "Epoch 29: 100%|██████████| 162/162 [00:03<00:00, 51.33it/s, v_num=0, val_loss=0.691, train_loss=0.690]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 162/162 [00:03<00:00, 51.01it/s, v_num=0, val_loss=0.691, train_loss=0.690]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/soheuny/miniconda3/envs/coffea_torch/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:653: Checkpoint directory /home/soheuny/HH4bsim/playground/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type       | Params\n",
      "----------------------------------------\n",
      "0 | encoder  | FvTEncoder | 920   \n",
      "1 | select_q | conv1d     | 8     \n",
      "2 | out      | conv1d     | 16    \n",
      "----------------------------------------\n",
      "895       Trainable params\n",
      "49        Non-trainable params\n",
      "944       Total params\n",
      "0.004     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4b ratio:  0.49899265\n",
      "Signal ratio:  0.08999999\n",
      "Epoch 29: 100%|██████████| 162/162 [00:02<00:00, 55.49it/s, v_num=0, val_loss=0.690, train_loss=0.689]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 162/162 [00:02<00:00, 55.12it/s, v_num=0, val_loss=0.690, train_loss=0.689]\n"
     ]
    }
   ],
   "source": [
    "n_3b = 250000\n",
    "n_all4b = 250000\n",
    "# signal_ratio = 0.05\n",
    "\n",
    "# for signal_ratio in [0, 0.0001, 0.0002, 0.0005, 0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1]:\n",
    "for signal_ratio in [0.03, 0.04, 0.06, 0.07, 0.08, 0.09]:\n",
    "    ###########################################################################################\n",
    "    ###########################################################################################\n",
    "\n",
    "    import pytorch_lightning as pl\n",
    "    from torch.utils.data import TensorDataset\n",
    "\n",
    "    np.random.seed(seed_)\n",
    "\n",
    "    features = [\"sym_canJet0_pt\", \"sym_canJet1_pt\", \"sym_canJet2_pt\", \"sym_canJet3_pt\",\n",
    "                \"sym_canJet0_eta\", \"sym_canJet1_eta\", \"sym_canJet2_eta\", \"sym_canJet3_eta\",\n",
    "                \"sym_canJet0_phi\", \"sym_canJet1_phi\", \"sym_canJet2_phi\", \"sym_canJet3_phi\",\n",
    "                \"sym_canJet0_m\", \"sym_canJet1_m\", \"sym_canJet2_m\", \"sym_canJet3_m\"]\n",
    "\n",
    "    pl.seed_everything(seed_)\n",
    "    np.random.seed(seed_)\n",
    "\n",
    "    test_ratio = 0.5\n",
    "\n",
    "    n_3b_train = int(n_3b * (1 - test_ratio))\n",
    "    n_all4b_train = int(n_all4b * (1 - test_ratio))\n",
    "    n_bg4b_train = n_all4b_train - int(n_all4b_train * signal_ratio)\n",
    "    n_hh4b_train = int(n_all4b_train * signal_ratio)\n",
    "\n",
    "\n",
    "    df_3b_train = df_3b.iloc[:n_3b_train]\n",
    "    df_bg4b_train = df_bg4b.iloc[:n_bg4b_train]\n",
    "    df_hh4b_train = df_hh4b.iloc[:n_hh4b_train]\n",
    "    # reweight to match signal_ratio\n",
    "    df_hh4b_train.loc[:, \"weight\"] = (signal_ratio / (1 - signal_ratio)) * (\n",
    "                                np.sum(df_bg4b_train[\"weight\"]) / np.sum(df_hh4b_train[\"weight\"])) * df_hh4b_train[\"weight\"]\n",
    "    df_train = pd.concat([df_3b_train, df_bg4b_train, df_hh4b_train])\n",
    "    # shuffle the data\n",
    "    df_train = df_train.sample(frac=1, random_state=seed_).reset_index(drop=True)\n",
    "\n",
    "    n_3b_test = n_3b - n_3b_train\n",
    "    n_all4b_test = n_all4b - n_all4b_train\n",
    "    n_bg4b_test = n_all4b_test - int(n_all4b_test * signal_ratio)\n",
    "    n_hh4b_test = int(n_all4b_test * signal_ratio)\n",
    "\n",
    "    df_3b_test = df_3b.iloc[n_3b_train:n_3b_train+n_3b_test]\n",
    "    df_bg4b_test = df_bg4b.iloc[n_bg4b_train:n_bg4b_train+n_bg4b_test]\n",
    "    df_hh4b_test = df_hh4b.iloc[n_hh4b_train:n_hh4b_train+n_hh4b_test]\n",
    "    df_hh4b_test.loc[:, \"weight\"] = (signal_ratio / (1 - signal_ratio)) * (\n",
    "                                np.sum(df_bg4b_test[\"weight\"]) / np.sum(df_hh4b_test[\"weight\"])) * df_hh4b_test[\"weight\"]\n",
    "    df_test = pd.concat([df_3b_test, df_bg4b_test, df_hh4b_test])\n",
    "    df_test = df_test.sample(frac=1, random_state=seed_).reset_index(drop=True)\n",
    "\n",
    "    # reduce number of 4b samples to 1/8\n",
    "    print(\"4b ratio: \", df_train.loc[df_train[\"fourTag\"], \"weight\"].sum() / df_train[\"weight\"].sum())\n",
    "    print(\"Signal ratio: \", df_train.loc[df_train[\"signal\"], \"weight\"].sum() / df_train.loc[df_train[\"fourTag\"], \"weight\"].sum())\n",
    "\n",
    "    # For ghostbatch, let len(train_indices) be a multiple of 32\n",
    "    split_at = 1024 * (int((2/3) * df_train.index.size) // 1024)\n",
    "    end_at = 1024 * (df_train.index.size // 1024)\n",
    "\n",
    "    X_train = torch.tensor(df_train[features].values, dtype=torch.float32)[:split_at]\n",
    "    w_train = torch.tensor(df_train[\"weight\"].values, dtype=torch.float32)[:split_at]\n",
    "    y_train = torch.tensor(df_train[\"fourTag\"].values, dtype=torch.long)[:split_at]\n",
    "    is_signal_train = torch.tensor(df_train[\"signal\"].values, dtype=torch.long)[:split_at]\n",
    "\n",
    "    X_val = torch.tensor(df_train[features].values, dtype=torch.float32)[split_at:end_at]\n",
    "    w_val = torch.tensor(df_train[\"weight\"].values, dtype=torch.float32)[split_at:end_at]\n",
    "    y_val = torch.tensor(df_train[\"fourTag\"].values, dtype=torch.long)[split_at:end_at]\n",
    "    is_signal_val = torch.tensor(df_train[\"signal\"].values, dtype=torch.long)[split_at:end_at]\n",
    "\n",
    "    train_dataset = TensorDataset(X_train, y_train, w_train)\n",
    "    val_dataset = TensorDataset(X_val, y_val, w_val)\n",
    "\n",
    "    ###########################################################################################\n",
    "    ###########################################################################################\n",
    "\n",
    "    from fvt_classifier import FvTClassifier\n",
    "\n",
    "    num_classes = 2\n",
    "    dim_input_jet_features = 4\n",
    "    dim_dijet_features = 6\n",
    "    dim_quadjet_features = 6\n",
    "    max_epochs = 30\n",
    "    run_name = \"_\".join([\"fvt_classifier_toy_signal_ratio\", \n",
    "                        f\"signal_ratio={signal_ratio}\", \n",
    "                        f\"dijet={dim_dijet_features}\", \n",
    "                        f\"quadjet={dim_quadjet_features}\", \n",
    "                        f\"n_3b={n_3b}\",\n",
    "                        f\"n_all4b={n_all4b}\",])\n",
    "    lr = 1e-3\n",
    "\n",
    "    pl.seed_everything(42)\n",
    "\n",
    "    model = FvTClassifier(num_classes, \n",
    "                        dim_input_jet_features, \n",
    "                        dim_dijet_features, \n",
    "                        dim_quadjet_features, \n",
    "                        run_name=run_name,\n",
    "                        device=torch.device(\"cuda:0\"),\n",
    "                        lr=lr)\n",
    "\n",
    "    model.fit(train_dataset, val_dataset, batch_size=1024, max_epochs=max_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "## SvB\n",
    "\n",
    "# pl.seed_everything(42)\n",
    "\n",
    "# num_classes = 2\n",
    "# dim_input_jet_features = 4\n",
    "# dim_dijet_features = 6\n",
    "# dim_quadjet_features = 6\n",
    "# max_epochs = 80\n",
    "# svb_run_name = \"_\".join([\"svb_classifier_toy_signal_ratio\", \n",
    "#                     f\"signal_ratio={signal_ratio}\", \n",
    "#                     f\"dijet={dim_dijet_features}\", \n",
    "#                     f\"quadjet={dim_quadjet_features}\", \n",
    "#                     f\"n_3b={n_3b}\",\n",
    "#                     f\"n_all4b={n_all4b}\",])\n",
    "# lr = 1e-3\n",
    "\n",
    "\n",
    "# model = FvTClassifier(num_classes, \n",
    "#                        dim_input_jet_features, \n",
    "#                        dim_dijet_features, \n",
    "#                        dim_quadjet_features, \n",
    "#                        run_name=svb_run_name,\n",
    "#                        device=torch.device(\"cuda:0\"),\n",
    "#                        lr=lr)\n",
    "\n",
    "\n",
    "# svb_train_dataset = TensorDataset(X_train, is_signal_train, w_train)\n",
    "# svb_val_dataset = TensorDataset(X_val, is_signal_val, w_val)\n",
    "\n",
    "# model.fit(svb_train_dataset, svb_val_dataset, batch_size=1024, max_epochs=max_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "# model = FvTClassifier.load_from_checkpoint(f\"./checkpoints/{svb_run_name}_best.ckpt\")\n",
    "model = FvTClassifier.load_from_checkpoint(f\"./checkpoints/{run_name}_best.ckpt\")\n",
    "val_loader = DataLoader(val_dataset, batch_size=1024, shuffle=False)\n",
    "device = torch.device(\"cuda:0\")\n",
    "model = model.to(device)\n",
    "\n",
    "q_repr_val = []\n",
    "\n",
    "for batch in val_loader:\n",
    "    x, y, w = batch\n",
    "    x = x.to(device)\n",
    "    q = model.encoder(x)\n",
    "    q_repr_val.append(q.detach().cpu().numpy())\n",
    "\n",
    "q_repr_val = np.concatenate(q_repr_val, axis=0)\n",
    "labels_4b_val = y_val.cpu().numpy()\n",
    "probs_4b_val = model.predict(X_val)[:, 1].cpu().numpy()\n",
    "weights_val = w_val.cpu().numpy()\n",
    "is_signal_val = is_signal_val.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from plots import plot_prob_weighted_histogram1d, calibration_plot\n",
    "%matplotlib inline\n",
    "plot_prob_weighted_histogram1d(probs_4b_val, probs_4b_val, labels_4b_val,\n",
    "                               n_bins=50, \n",
    "                               sample_weights=weights_val,\n",
    "                               ylim=(0.5, 1.5))\n",
    "calibration_plot(probs_4b_val, labels_4b_val,\n",
    "                 bins=50,\n",
    "                 sample_weights=weights_val)\n",
    "\n",
    "# plot_prob_weighted_histogram1d(probs_4b_val, probs_4b_val, is_signal_val,\n",
    "#                                n_bins=50, \n",
    "#                                sample_weights=weights_val,\n",
    "#                                ylim=(0.5, 1.5))\n",
    "# calibration_plot(probs_4b_val, is_signal_val,\n",
    "#                  bins=50,\n",
    "#                  sample_weights=weights_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "fig = plt.figure(figsize=(10, 3.5 * 2 * dim_quadjet_features))\n",
    "outer = gridspec.GridSpec(2*dim_quadjet_features, 3, hspace=1.5, wspace=0.3)\n",
    "\n",
    "is_3b_val = labels_4b_val == 0\n",
    "is_4b_val = labels_4b_val == 1\n",
    "is_bg4b_val = (labels_4b_val == 1) & (is_signal_val == 0)\n",
    "is_hh4b_val = (labels_4b_val == 1) & (is_signal_val == 1)\n",
    "plot_density = True\n",
    "\n",
    "for i in range(dim_quadjet_features):\n",
    "    for j in range(3):\n",
    "        \n",
    "        repr_min, repr_max = np.min(q_repr_val[:, i, j]), np.max(q_repr_val[:, i, j])\n",
    "        bins_range = np.linspace(repr_min, repr_max, 50)\n",
    "        \n",
    "        inner = gridspec.GridSpecFromSubplotSpec(4, 1, subplot_spec=outer[2*i:2*(i+1), j], hspace=0.2, height_ratios=[1, 1, 1, 1])\n",
    "        current_ax = plt.Subplot(fig, inner[0])\n",
    "        current_ax.hist(q_repr_val[is_3b_val, i, j], bins=bins_range, label=\"bg 3b\", linewidth=1, histtype=\"step\", density=True, weights=weights_val[is_3b_val])\n",
    "        current_ax.hist(q_repr_val[is_bg4b_val, i, j], bins=bins_range, label=\"bg 4b\", linewidth=1, histtype=\"step\", density=True, weights=weights_val[is_bg4b_val])\n",
    "        current_ax.hist(q_repr_val[is_hh4b_val, i, j], bins=bins_range, label=\"HH 4b\", linewidth=1, histtype=\"step\", density=True, weights=weights_val[is_hh4b_val])\n",
    "        # calculate distance between two histograms (total variation distance)\n",
    "        # tvd = 0.5 * np.sum(np.abs(repr_hist_3b - repr_hist_4b))\n",
    "        current_ax.set_title(f\"View {j}, Feature {i}\")\n",
    "        # remove x labels\n",
    "        current_ax.set_xticks([])\n",
    "        current_ax.legend()\n",
    "        fig.add_subplot(current_ax)\n",
    "\n",
    "        current_ax = plt.Subplot(fig, inner[1])\n",
    "\n",
    "        current_ax.hist(q_repr_val[is_3b_val, i, j], bins=bins_range, label=\"bg 3b\", linewidth=1, histtype=\"step\", density=False, weights=weights_val[is_3b_val])\n",
    "        current_ax.hist(q_repr_val[is_bg4b_val, i, j], bins=bins_range, label=\"bg 4b\", linewidth=1, histtype=\"step\", density=False, weights=weights_val[is_bg4b_val])\n",
    "        current_ax.hist(q_repr_val[is_hh4b_val, i, j], bins=bins_range, label=\"HH 4b\", linewidth=1, histtype=\"step\", density=False, weights=weights_val[is_hh4b_val])\n",
    "        # calculate distance between two histograms (total variation distance)\n",
    "        # tvd = 0.5 * np.sum(np.abs(repr_hist_3b - repr_hist_4b))\n",
    "        # current_ax.set_title(f\"View {j}, Feature {i}\")\n",
    "        # remove x labels\n",
    "        current_ax.set_xticks([])\n",
    "        current_ax.legend()\n",
    "        fig.add_subplot(current_ax)\n",
    "\n",
    "        current_ax = plt.Subplot(fig, inner[2])\n",
    "        current_ax.hist(q_repr_val[is_3b_val, i, j], bins=bins_range, label=\"3b\", linewidth=1, histtype=\"step\", density=True, weights=weights_val[is_3b_val])\n",
    "        current_ax.hist(q_repr_val[is_4b_val, i, j], bins=bins_range, label=\"all 4b\", linewidth=1, histtype=\"step\", density=True, weights=weights_val[is_4b_val])\n",
    "        # calculate distance between two histograms (total variation distance)\n",
    "        # current_ax.set_title(f\"View {j}, Feature {i}, TV: {tvd:.2f}\")\n",
    "        # remove x labels\n",
    "        current_ax.set_xticks([])\n",
    "        current_ax.legend()\n",
    "\n",
    "        fig.add_subplot(current_ax)\n",
    "        current_ax = plt.Subplot(fig, inner[3])\n",
    "        current_ax.hist(q_repr_val[is_3b_val, i, j], bins=bins_range, label=\"3b\", linewidth=1, histtype=\"step\", density=False, weights=weights_val[is_3b_val])\n",
    "        current_ax.hist(q_repr_val[is_4b_val, i, j], bins=bins_range, label=\"all 4b\", linewidth=1, histtype=\"step\", density=False, weights=weights_val[is_4b_val])\n",
    "        # calculate distance between two histograms (total variation distance)\n",
    "        # current_ax.set_title(f\"View {j}, Feature {i}, TV: {tvd:.2f}\")\n",
    "        # remove x labels\n",
    "        current_ax.legend()\n",
    "        fig.add_subplot(current_ax)\n",
    "\n",
    "\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "bins_range = np.linspace(0, 1, 50)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(probs_4b_val[is_3b_val], bins=bins_range, label=\"bg 3b\", linewidth=1, histtype=\"step\", density=False, weights=weights_val[is_3b_val])\n",
    "ax.hist(probs_4b_val[is_bg4b_val], bins=bins_range, label=\"bg 4b\", linewidth=1, histtype=\"step\", density=False, weights=weights_val[is_bg4b_val])\n",
    "ax.hist(probs_4b_val[is_hh4b_val], bins=bins_range, label=\"HH 4b\", linewidth=1, histtype=\"step\", density=False, weights=weights_val[is_hh4b_val])\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"FvT output\")\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(probs_4b_val[is_3b_val], bins=bins_range, label=\"bg 3b\", linewidth=1, histtype=\"step\", density=False, weights=weights_val[is_3b_val])\n",
    "ax.hist(probs_4b_val[is_4b_val], bins=bins_range, label=\"all 4b\", linewidth=1, histtype=\"step\", density=False, weights=weights_val[is_4b_val])\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"FvT output\")\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test dataset (Not validation dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "print(\"Test Data\")\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "end_at = 1024 * (df_test.index.size // 1024)\n",
    "\n",
    "X_test = torch.tensor(df_test[features].values[:end_at], dtype=torch.float32)\n",
    "w_test = torch.tensor(df_test[\"weight\"].values[:end_at], dtype=torch.float32)\n",
    "y_test = torch.tensor(df_test[\"fourTag\"].values[:end_at], dtype=torch.long)\n",
    "is_signal_test = torch.tensor(df_test[\"signal\"].values[:end_at], dtype=torch.long)\n",
    "svb_test_dataset = TensorDataset(X_test, y_test, w_test)\n",
    "\n",
    "fvt_model = FvTClassifier.load_from_checkpoint(f\"./checkpoints/{run_name}_best.ckpt\")\n",
    "test_loader = DataLoader(svb_test_dataset, batch_size=1024, shuffle=False)\n",
    "device = torch.device(\"cuda:0\")\n",
    "fvt_model = fvt_model.to(device)\n",
    "\n",
    "q_repr_test = []\n",
    "\n",
    "for batch in test_loader:\n",
    "    x, y, w = batch\n",
    "    x = x.to(device)\n",
    "    q = fvt_model.encoder(x)\n",
    "    q_repr_test.append(q.detach().cpu().numpy())\n",
    "\n",
    "q_repr_test = np.concatenate(q_repr_test, axis=0)\n",
    "labels_4b_test = y_test.cpu().numpy()\n",
    "probs_4b_test = fvt_model.predict(X_test)[:, 1].cpu().numpy()\n",
    "weights_test = w_test.cpu().numpy()\n",
    "is_signal_test = is_signal_test.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "print(\"**Test Data**\")\n",
    "\n",
    "\n",
    "plot_prob_weighted_histogram1d(probs_4b_test, probs_4b_test, labels_4b_test,\n",
    "                               n_bins=50, \n",
    "                               sample_weights=weights_test,\n",
    "                               ylim=(0.5, 1.5))\n",
    "calibration_plot(probs_4b_test, labels_4b_test,\n",
    "                 bins=50,\n",
    "                 sample_weights=weights_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "fig = plt.figure(figsize=(10, 3.5 * 2 * dim_quadjet_features))\n",
    "outer = gridspec.GridSpec(2*dim_quadjet_features, 3, hspace=1.5, wspace=0.3)\n",
    "\n",
    "is_3b_test = labels_4b_test == 0\n",
    "is_4b_test = labels_4b_test == 1\n",
    "is_bg4b_test = (labels_4b_test == 1) & (is_signal_test == 0)\n",
    "is_hh4b_test = (labels_4b_test == 1) & (is_signal_test == 1)\n",
    "plot_density = True\n",
    "\n",
    "for i in range(dim_quadjet_features):\n",
    "    for j in range(3):\n",
    "        \n",
    "        repr_min, repr_max = np.min(q_repr_test[:, i, j]), np.max(q_repr_test[:, i, j])\n",
    "        bins_range = np.linspace(repr_min, repr_max, 50)\n",
    "        \n",
    "        inner = gridspec.GridSpecFromSubplotSpec(4, 1, subplot_spec=outer[2*i:2*(i+1), j], hspace=0.2, height_ratios=[1, 1, 1, 1])\n",
    "        current_ax = plt.Subplot(fig, inner[0])\n",
    "        current_ax.hist(q_repr_test[is_3b_test, i, j], bins=bins_range, label=\"bg 3b\", linewidth=1, histtype=\"step\", density=True, weights=weights_test[is_3b_test])\n",
    "        current_ax.hist(q_repr_test[is_bg4b_test, i, j], bins=bins_range, label=\"bg 4b\", linewidth=1, histtype=\"step\", density=True, weights=weights_test[is_bg4b_test])\n",
    "        current_ax.hist(q_repr_test[is_hh4b_test, i, j], bins=bins_range, label=\"HH 4b\", linewidth=1, histtype=\"step\", density=True, weights=weights_test[is_hh4b_test])\n",
    "        # calculate distance between two histograms (total variation distance)\n",
    "        # tvd = 0.5 * np.sum(np.abs(repr_hist_3b - repr_hist_4b))\n",
    "        current_ax.set_title(f\"View {j}, Feature {i}\")\n",
    "        # remove x labels\n",
    "        current_ax.set_xticks([])\n",
    "        current_ax.legend()\n",
    "        fig.add_subplot(current_ax)\n",
    "\n",
    "        current_ax = plt.Subplot(fig, inner[1])\n",
    "\n",
    "        current_ax.hist(q_repr_test[is_3b_test, i, j], bins=bins_range, label=\"bg 3b\", linewidth=1, histtype=\"step\", density=False, weights=weights_test[is_3b_test])\n",
    "        current_ax.hist(q_repr_test[is_bg4b_test, i, j], bins=bins_range, label=\"bg 4b\", linewidth=1, histtype=\"step\", density=False, weights=weights_test[is_bg4b_test])\n",
    "        current_ax.hist(q_repr_test[is_hh4b_test, i, j], bins=bins_range, label=\"HH 4b\", linewidth=1, histtype=\"step\", density=False, weights=weights_test[is_hh4b_test])\n",
    "        # calculate distance between two histograms (total variation distance)\n",
    "        # tvd = 0.5 * np.sum(np.abs(repr_hist_3b - repr_hist_4b))\n",
    "        # current_ax.set_title(f\"View {j}, Feature {i}\")\n",
    "        # remove x labels\n",
    "        current_ax.set_xticks([])\n",
    "        current_ax.legend()\n",
    "        fig.add_subplot(current_ax)\n",
    "\n",
    "        current_ax = plt.Subplot(fig, inner[2])\n",
    "        current_ax.hist(q_repr_test[is_3b_test, i, j], bins=bins_range, label=\"3b\", linewidth=1, histtype=\"step\", density=True, weights=weights_test[is_3b_test])\n",
    "        current_ax.hist(q_repr_test[is_4b_test, i, j], bins=bins_range, label=\"all 4b\", linewidth=1, histtype=\"step\", density=True, weights=weights_test[is_4b_test])\n",
    "        # calculate distance between two histograms (total variation distance)\n",
    "        # current_ax.set_title(f\"View {j}, Feature {i}, TV: {tvd:.2f}\")\n",
    "        # remove x labels\n",
    "        current_ax.set_xticks([])\n",
    "        current_ax.legend()\n",
    "\n",
    "        fig.add_subplot(current_ax)\n",
    "        current_ax = plt.Subplot(fig, inner[3])\n",
    "        current_ax.hist(q_repr_test[is_3b_test, i, j], bins=bins_range, label=\"3b\", linewidth=1, histtype=\"step\", density=False, weights=weights_test[is_3b_test])\n",
    "        current_ax.hist(q_repr_test[is_4b_test, i, j], bins=bins_range, label=\"all 4b\", linewidth=1, histtype=\"step\", density=False, weights=weights_test[is_4b_test])\n",
    "        # calculate distance between two histograms (total variation distance)\n",
    "        # current_ax.set_title(f\"View {j}, Feature {i}, TV: {tvd:.2f}\")\n",
    "        # remove x labels\n",
    "        current_ax.legend()\n",
    "        fig.add_subplot(current_ax)\n",
    "\n",
    "\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "bins_range = np.linspace(0, 1, 50)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(probs_4b_test[is_3b_test], bins=bins_range, label=\"bg 3b\", linewidth=1, histtype=\"step\", density=False, weights=weights_test[is_3b_test])\n",
    "ax.hist(probs_4b_test[is_bg4b_test], bins=bins_range, label=\"bg 4b\", linewidth=1, histtype=\"step\", density=False, weights=weights_test[is_bg4b_test])\n",
    "ax.hist(probs_4b_test[is_hh4b_test], bins=bins_range, label=\"HH 4b\", linewidth=1, histtype=\"step\", density=False, weights=weights_test[is_hh4b_test])\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"FvT output\")\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(probs_4b_test[is_3b_test], bins=bins_range, label=\"bg 3b\", linewidth=1, histtype=\"step\", density=False, weights=weights_test[is_3b_test])\n",
    "ax.hist(probs_4b_test[is_4b_test], bins=bins_range, label=\"all 4b\", linewidth=1, histtype=\"step\", density=False, weights=weights_test[is_4b_test])\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"FvT output\")\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "fig = plt.figure(figsize=(10, 3.5 * 2 * dim_quadjet_features))\n",
    "outer = gridspec.GridSpec(2*dim_quadjet_features, 3, hspace=1.5, wspace=0.3)\n",
    "\n",
    "for i in range(dim_quadjet_features):\n",
    "    for j in range(3):\n",
    "        \n",
    "        repr_min, repr_max = np.min(q_repr_test[:, i, j]), np.max(q_repr_test[:, i, j])\n",
    "        bins_range = np.linspace(repr_min, repr_max, 50)\n",
    "        \n",
    "        inner = gridspec.GridSpecFromSubplotSpec(4, 1, subplot_spec=outer[2*i:2*(i+1), j], hspace=0.2, height_ratios=[1, 1, 1, 1])\n",
    "        current_ax = plt.Subplot(fig, inner[0])\n",
    "        current_ax.hist(q_repr_test[is_3b_test, i, j], bins=bins_range, label=\"bg 3b\", linewidth=1, histtype=\"step\", density=True, weights=weights_test[is_3b_test])\n",
    "        current_ax.hist(q_repr_test[is_bg4b_test, i, j], bins=bins_range, label=\"bg 4b\", linewidth=1, histtype=\"step\", density=True, weights=weights_test[is_bg4b_test])\n",
    "        current_ax.hist(q_repr_test[is_hh4b_test, i, j], bins=bins_range, label=\"HH 4b\", linewidth=1, histtype=\"step\", density=True, weights=weights_test[is_hh4b_test])\n",
    "        current_ax.set_title(f\"View {j}, Feature {i}\")\n",
    "        # remove x labels\n",
    "        current_ax.set_xticks([])\n",
    "        current_ax.legend()\n",
    "        fig.add_subplot(current_ax)\n",
    "\n",
    "        current_ax = plt.Subplot(fig, inner[1])\n",
    "\n",
    "        current_ax.hist(q_repr_test[is_3b_test, i, j], bins=bins_range, label=\"bg 3b\", linewidth=1, histtype=\"step\", density=False, weights=weights_test[is_3b_test])\n",
    "        current_ax.hist(q_repr_test[is_bg4b_test, i, j], bins=bins_range, label=\"bg 4b\", linewidth=1, histtype=\"step\", density=False, weights=weights_test[is_bg4b_test])\n",
    "        current_ax.hist(q_repr_test[is_hh4b_test, i, j], bins=bins_range, label=\"HH 4b\", linewidth=1, histtype=\"step\", density=False, weights=weights_test[is_hh4b_test])\n",
    "        # current_ax.set_title(f\"View {j}, Feature {i}\")\n",
    "        # remove x labels\n",
    "        current_ax.set_xticks([])\n",
    "        current_ax.legend()\n",
    "        fig.add_subplot(current_ax)\n",
    "\n",
    "        current_ax = plt.Subplot(fig, inner[2])\n",
    "        current_ax.hist(q_repr_test[is_3b_test, i, j], bins=bins_range, label=\"3b\", linewidth=1, histtype=\"step\", density=True, weights=weights_test[is_3b_test])\n",
    "        current_ax.hist(q_repr_test[is_4b_test, i, j], bins=bins_range, label=\"all 4b\", linewidth=1, histtype=\"step\", density=True, weights=weights_test[is_4b_test])\n",
    "        # current_ax.set_title(f\"View {j}, Feature {i}, TV: {tvd:.2f}\")\n",
    "        # remove x labels\n",
    "        current_ax.set_xticks([])\n",
    "        current_ax.legend()\n",
    "\n",
    "        fig.add_subplot(current_ax)\n",
    "        current_ax = plt.Subplot(fig, inner[3])\n",
    "        current_ax.hist(q_repr_test[is_3b_test, i, j], bins=bins_range, label=\"3b\", linewidth=1, histtype=\"step\", density=False, weights=weights_test[is_3b_test])\n",
    "        current_ax.hist(q_repr_test[is_4b_test, i, j], bins=bins_range, label=\"all 4b\", linewidth=1, histtype=\"step\", density=False, weights=weights_test[is_4b_test])\n",
    "        # current_ax.set_title(f\"View {j}, Feature {i}, TV: {tvd:.2f}\")\n",
    "        # remove x labels\n",
    "        current_ax.legend()\n",
    "        fig.add_subplot(current_ax)\n",
    "\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "n_points = min(np.sum(is_3b_test), np.sum(is_bg4b_test), np.sum(is_hh4b_test))\n",
    "\n",
    "is_3b_plot = np.random.choice(np.where(is_3b_test)[0], n_points, replace=False)\n",
    "is_bg4b_plot = np.random.choice(np.where(is_bg4b_test)[0], n_points, replace=False)\n",
    "is_hh4b_plot = np.random.choice(np.where(is_hh4b_test)[0], n_points, replace=False)\n",
    "\n",
    "for i in range(dim_quadjet_features):\n",
    "    fig = go.Figure()\n",
    "    fig.update_layout(width=600, height=600)\n",
    "    fig.update_layout(title=f\"Feature {i}\")\n",
    "    fig.update_layout(hovermode=False)\n",
    "    fig.add_trace(go.Scatter3d\n",
    "                    (x=q_repr_test[is_3b_plot, i, 0], y=q_repr_test[is_3b_plot, i, 1], z=q_repr_test[is_3b_plot, i, 2], mode='markers', name='bg 3b', marker=dict(size=3, color=\"blue\", opacity=0.4)))\n",
    "    fig.add_trace(go.Scatter3d\n",
    "                    (x=q_repr_test[is_bg4b_plot, i, 0], y=q_repr_test[is_bg4b_plot, i, 1], z=q_repr_test[is_bg4b_plot, i, 2], mode='markers', name='bg 4b', marker=dict(size=3, color=\"orange\", opacity=0.4)))\n",
    "    fig.add_trace(go.Scatter3d\n",
    "                    (x=q_repr_test[is_hh4b_plot, i, 0], y=q_repr_test[is_hh4b_plot, i, 1], z=q_repr_test[is_hh4b_plot, i, 2], mode='markers', name='HH 4b', marker=dict(size=3, color=\"green\"))\n",
    "                    )\n",
    "    fig.update_layout(scene=dict(xaxis_title=f\"View 0\", yaxis_title=f\"View 1\", zaxis_title=f\"View 2\"))\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pair plots with prob4b threshold\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(probs_4b_test[is_3b_test], bins=bins_range, label=\"bg 3b\", linewidth=1, histtype=\"step\", density=False, weights=weights_test[is_3b_test])\n",
    "ax.hist(probs_4b_test[is_bg4b_test], bins=bins_range, label=\"bg 4b\", linewidth=1, histtype=\"step\", density=False, weights=weights_test[is_bg4b_test])\n",
    "ax.hist(probs_4b_test[is_hh4b_test], bins=bins_range, label=\"HH 4b\", linewidth=1, histtype=\"step\", density=False, weights=weights_test[is_hh4b_test])\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"FvT output\")\n",
    "plt.show()\n",
    "\n",
    "probs_4b_threshold = 0.6\n",
    "probs_4b_exceeded = probs_4b_test > probs_4b_threshold\n",
    "\n",
    "n_points = min(np.sum(is_3b_test & probs_4b_exceeded), np.sum(is_bg4b_test & probs_4b_exceeded), np.sum(is_hh4b_test & probs_4b_exceeded))\n",
    "print(f\"Plotting {n_points} per class with prob4b > {probs_4b_threshold}\")\n",
    "\n",
    "is_3b_plot = np.random.choice(np.where(is_3b_test & probs_4b_exceeded)[0], n_points, replace=False)\n",
    "is_bg4b_plot = np.random.choice(np.where(is_bg4b_test & probs_4b_exceeded)[0], n_points, replace=False)\n",
    "is_hh4b_plot = np.random.choice(np.where(is_hh4b_test & probs_4b_exceeded)[0], n_points, replace=False)\n",
    "\n",
    "for i in range(dim_quadjet_features):\n",
    "    fig = go.Figure()\n",
    "    fig.update_layout(width=600, height=600)\n",
    "    fig.update_layout(title=f\"Feature {i}\")\n",
    "    fig.update_layout(hovermode=False)\n",
    "    fig.add_trace(go.Scatter3d\n",
    "                    (x=q_repr_test[is_3b_plot, i, 0], y=q_repr_test[is_3b_plot, i, 1], z=q_repr_test[is_3b_plot, i, 2], mode='markers', name='bg 3b', marker=dict(size=3, color=\"blue\")))\n",
    "    fig.add_trace(go.Scatter3d\n",
    "                    (x=q_repr_test[is_bg4b_plot, i, 0], y=q_repr_test[is_bg4b_plot, i, 1], z=q_repr_test[is_bg4b_plot, i, 2], mode='markers', name='bg 4b', marker=dict(size=3, color=\"orange\")))\n",
    "    fig.add_trace(go.Scatter3d\n",
    "                    (x=q_repr_test[is_hh4b_plot, i, 0], y=q_repr_test[is_hh4b_plot, i, 1], z=q_repr_test[is_hh4b_plot, i, 2], mode='markers', name='HH 4b', marker=dict(size=3, color=\"green\"))\n",
    "                    )\n",
    "    fig.update_layout(scene=dict(xaxis_title=f\"View 0\", yaxis_title=f\"View 1\", zaxis_title=f\"View 2\"))\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TSNE\n",
    "from sklearn.manifold import TSNE\n",
    "np.random.seed(seed_)\n",
    "\n",
    "q_repr_and_probs_4b = np.concatenate([q_repr_test.reshape(-1, 3 * dim_quadjet_features), probs_4b_test.reshape(-1, 1)], axis=1)\n",
    "\n",
    "n_components = 1\n",
    "for probs_4b_threshold in [0.0, 0.4, 0.5, 0.6, 0.7]:\n",
    "    probs_4b_exceeded = probs_4b_test > probs_4b_threshold\n",
    "    n_sample_clustering = min(np.sum(probs_4b_exceeded), 10000)\n",
    "    np.random.seed(seed_)\n",
    "    idx_clustering = np.random.choice(np.where(probs_4b_exceeded)[0], n_sample_clustering, replace=False)\n",
    "\n",
    "    is_3b_cluster = is_3b_test[idx_clustering]\n",
    "    is_bg4b_cluster = is_bg4b_test[idx_clustering]\n",
    "    is_hh4b_cluster = is_hh4b_test[idx_clustering]\n",
    "\n",
    "    # Initialize t-SNE\n",
    "    tsne = TSNE(n_components=n_components, random_state=seed_)  # n_components is the dimension of the embedded space\n",
    "\n",
    "    # Apply t-SNE to your data\n",
    "    embedded_data = tsne.fit_transform(q_repr_and_probs_4b[idx_clustering])\n",
    "    # save embedded data\n",
    "    np.save(f\"data/tsne_embedding_n_components_{n_components}_probs_4b_thr_{probs_4b_threshold}_seed_{seed_}.npy\", embedded_data)\n",
    "    np.save(f\"data/tsne_labels_n_components_{n_components}_probs_4b_thr_{probs_4b_threshold}_seed_{seed_}.npy\", np.stack([is_3b_cluster, is_bg4b_cluster, is_hh4b_cluster], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 3\n",
    "probs_4b_threshold = 0.0\n",
    "seed_ = 42\n",
    "\n",
    "embedded_data = np.load(f\"data/tsne_embedding_n_components_{n_components}_probs_4b_thr_{probs_4b_threshold}_seed_{seed_}.npy\")\n",
    "labels = np.load(f\"data/tsne_labels_n_components_{n_components}_probs_4b_thr_{probs_4b_threshold}_seed_{seed_}.npy\")\n",
    "\n",
    "is_3b_cluster = labels[:, 0]\n",
    "is_bg4b_cluster = labels[:, 1]\n",
    "is_hh4b_cluster = labels[:, 2]\n",
    "\n",
    "# 3d plot of TSNE\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.update_layout(width=600, height=600)\n",
    "fig.update_layout(hovermode=False)\n",
    "fig.add_trace(go.Scatter3d\n",
    "                (x=embedded_data[is_3b_cluster, 0], y=embedded_data[is_3b_cluster, 1], z=embedded_data[is_3b_cluster, 2], mode='markers', name='bg 3b', marker=dict(size=3, color=\"blue\", opacity=0.2)))\n",
    "fig.add_trace(go.Scatter3d\n",
    "                (x=embedded_data[is_bg4b_cluster, 0], y=embedded_data[is_bg4b_cluster, 1], z=embedded_data[is_bg4b_cluster, 2], mode='markers', name='bg 4b', marker=dict(size=3, color=\"orange\", opacity=0.2)))\n",
    "fig.add_trace(go.Scatter3d\n",
    "                (x=embedded_data[is_hh4b_cluster, 0], y=embedded_data[is_hh4b_cluster, 1], z=embedded_data[is_hh4b_cluster, 2], mode='markers', name='HH 4b', marker=dict(size=3, color=\"green\"))\n",
    "                )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(10, 5))\n",
    "\n",
    "ax[0].hist(embedded_data[is_3b_cluster, 0], label=\"3b\", histtype=\"step\")\n",
    "ax[0].hist(embedded_data[is_bg4b_cluster, 0], label=\"bg4b\", histtype=\"step\")\n",
    "ax[0].hist(embedded_data[is_hh4b_cluster, 0], label=\"hh4b\", histtype=\"step\")\n",
    "ax[0].set_xlabel('Component 1')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].hist(embedded_data[is_3b_cluster, 1], label=\"3b\", histtype=\"step\")\n",
    "ax[1].hist(embedded_data[is_bg4b_cluster, 1], label=\"bg4b\", histtype=\"step\")\n",
    "ax[1].hist(embedded_data[is_hh4b_cluster, 1], label=\"hh4b\", histtype=\"step\")\n",
    "ax[1].set_xlabel('Component 2')\n",
    "ax[1].legend()\n",
    "\n",
    "ax[2].hist(embedded_data[is_3b_cluster, 2], label=\"3b\", histtype=\"step\")\n",
    "ax[2].hist(embedded_data[is_bg4b_cluster, 2], label=\"bg4b\", histtype=\"step\")\n",
    "ax[2].hist(embedded_data[is_hh4b_cluster, 2], label=\"hh4b\", histtype=\"step\")\n",
    "ax[2].set_xlabel('Component 3')\n",
    "ax[2].legend()\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 1\n",
    "probs_4b_threshold = 0.5\n",
    "seed_ = 42\n",
    "\n",
    "embedded_data = np.load(f\"data/tsne_embedding_n_components_{n_components}_probs_4b_thr_{probs_4b_threshold}_seed_{seed_}.npy\")\n",
    "labels = np.load(f\"data/tsne_labels_n_components_{n_components}_probs_4b_thr_{probs_4b_threshold}_seed_{seed_}.npy\")\n",
    "\n",
    "is_3b_cluster = labels[:, 0]\n",
    "is_bg4b_cluster = labels[:, 1]\n",
    "is_hh4b_cluster = labels[:, 2]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "bins_range = np.linspace(np.min(embedded_data), np.max(embedded_data), 30)\n",
    "ax.hist(embedded_data[is_3b_cluster, 0], label=\"3b\", histtype=\"step\", bins=bins_range)\n",
    "ax.hist(embedded_data[is_bg4b_cluster, 0], label=\"bg4b\", histtype=\"step\", bins=bins_range)\n",
    "ax.hist(embedded_data[is_hh4b_cluster, 0], label=\"hh4b\", histtype=\"step\", bins=bins_range)\n",
    "ax.set_xlabel('Component 1')\n",
    "ax.legend()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refit Classifier with thresholded data\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "\n",
    "probs_4b_threshold = 0.6\n",
    "\n",
    "probs_4b_exceeded_val = probs_4b_val > probs_4b_threshold\n",
    "q_repr_thresholded_val = q_repr_val[probs_4b_exceeded_val]\n",
    "labels_4b_thresholded_val = labels_4b_val[probs_4b_exceeded_val]\n",
    "weights_thresholded_val = weights_val[probs_4b_exceeded_val]\n",
    "probs_4b_thresholded_val = probs_4b_val[probs_4b_exceeded_val]\n",
    "\n",
    "probs_4b_exceeded_test = probs_4b_test > probs_4b_threshold\n",
    "q_repr_thresholded_test = q_repr_test[probs_4b_exceeded_test]\n",
    "labels_4b_thresholded_test = labels_4b_test[probs_4b_exceeded_test]\n",
    "weights_thresholded_test = weights_test[probs_4b_exceeded_test]\n",
    "probs_4b_thresholded_test = probs_4b_test[probs_4b_exceeded_test]\n",
    "\n",
    "fpr, tpr, _ = roc_curve(labels_4b_thresholded_test, probs_4b_thresholded_test, sample_weight=weights_thresholded_test)\n",
    "roc_auc = roc_auc_score(labels_4b_thresholded_test, probs_4b_thresholded_test, sample_weight=weights_thresholded_test)\n",
    "\n",
    "# refit\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "refit_clf = MLPClassifier(hidden_layer_sizes=(100, 100), max_iter=1000, random_state=seed_)\n",
    "refit_clf.fit(q_repr_thresholded_val.reshape(-1, 3*dim_quadjet_features), labels_4b_thresholded_val)\n",
    "\n",
    "probs_4b_refit = refit_clf.predict_proba(q_repr_thresholded_test.reshape(-1, 3*dim_quadjet_features))[:, 1]\n",
    "auc_refit = roc_auc_score(labels_4b_thresholded_test, probs_4b_refit, sample_weight=weights_thresholded_test)\n",
    "fpr_refit, tpr_refit, _ = roc_curve(labels_4b_thresholded_test, probs_4b_refit, sample_weight=weights_thresholded_test)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(fpr, tpr, label=f\"FvT ROC AUC: {roc_auc:.3f}\")\n",
    "ax.plot(fpr_refit, tpr_refit, label=f\"Refit ROC AUC: {auc_refit:.3f}\")\n",
    "ax.plot([0, 1], [0, 1], linestyle=\"--\")\n",
    "ax.set_xlabel(\"False Positive Rate\")\n",
    "ax.set_ylabel(\"True Positive Rate\")\n",
    "ax.legend()\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# bins_range = np.linspace(0, 1, 50)\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.hist(probs_4b_refit[is_3b_test], bins=bins_range, label=\"bg 3b\", linewidth=1, histtype=\"step\", density=False, weights=weights_test[is_3b_test])\n",
    "# ax.hist(probs_4b_refit[is_bg4b_test], bins=bins_range, label=\"bg 4b\", linewidth=1, histtype=\"step\", density=False, weights=weights_test[is_bg4b_test])\n",
    "# ax.hist(probs_4b_refit[is_hh4b_test], bins=bins_range, label=\"HH 4b\", linewidth=1, histtype=\"step\", density=False, weights=weights_test[is_hh4b_test])\n",
    "# ax.legend()\n",
    "# ax.set_xlabel(\"FvT output\")\n",
    "# plt.show()\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.hist(probs_4b_refit[is_3b_test], bins=bins_range, label=\"bg 3b\", linewidth=1, histtype=\"step\", density=False, weights=weights_test[is_3b_test])\n",
    "# ax.hist(probs_4b_refit[is_4b_test], bins=bins_range, label=\"all 4b\", linewidth=1, histtype=\"step\", density=False, weights=weights_test[is_4b_test])\n",
    "# ax.legend()\n",
    "# ax.set_xlabel(\"FvT output\")\n",
    "# plt.show()\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "print(\"HH4B Data\")\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "end_at = 1024 * (df_hh4b.index.size // 1024)\n",
    "\n",
    "X_hh4b = torch.tensor(df_hh4b[features].values[:end_at], dtype=torch.float32)\n",
    "w_hh4b = torch.tensor(df_hh4b[\"weight\"].values[:end_at], dtype=torch.float32)\n",
    "y_hh4b = torch.tensor(df_hh4b[\"fourTag\"].values[:end_at], dtype=torch.long)\n",
    "is_signal_hh4b = torch.tensor(df_hh4b[\"signal\"].values[:end_at], dtype=torch.long)\n",
    "hh4b_dataset = TensorDataset(X_hh4b, y_hh4b, w_hh4b)\n",
    "\n",
    "fvt_model = FvTClassifier.load_from_checkpoint(f\"./checkpoints/{run_name}_best.ckpt\")\n",
    "hh4b_loader = DataLoader(hh4b_dataset, batch_size=1024, shuffle=False)\n",
    "device = torch.device(\"cuda:0\")\n",
    "fvt_model = fvt_model.to(device)\n",
    "\n",
    "q_repr_hh4b = []\n",
    "\n",
    "for batch in hh4b_loader:\n",
    "    x, y, w = batch\n",
    "    x = x.to(device)\n",
    "    q = fvt_model.encoder(x)\n",
    "    q_repr_hh4b.append(q.detach().cpu().numpy())\n",
    "\n",
    "q_repr_hh4b = np.concatenate(q_repr_hh4b, axis=0)\n",
    "labels_4b_hh4b = y_hh4b.cpu().numpy()\n",
    "probs_4b_hh4b = fvt_model.predict(X_hh4b)[:, 1].cpu().numpy()\n",
    "weights_hh4b = w_hh4b.cpu().numpy()\n",
    "is_signal_hh4b = is_signal_hh4b.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "fig = plt.figure(figsize=(10, 3.5 * 2 * dim_quadjet_features))\n",
    "outer = gridspec.GridSpec(2*dim_quadjet_features, 3, hspace=1.5, wspace=0.3)\n",
    "\n",
    "is_3b_test = labels_4b_test == 0\n",
    "is_4b_test = labels_4b_test == 1\n",
    "is_bg4b_test = (labels_4b_test == 1) & (is_signal_test == 0)\n",
    "is_hh4b_test = (labels_4b_test == 1) & (is_signal_test == 1)\n",
    "plot_density = True\n",
    "\n",
    "for i in range(dim_quadjet_features):\n",
    "    for j in range(3):\n",
    "        \n",
    "        repr_min, repr_max = np.min(q_repr_test[:, i, j]), np.max(q_repr_test[:, i, j])\n",
    "        bins_range = np.linspace(repr_min, repr_max, 50)\n",
    "        \n",
    "        inner = gridspec.GridSpecFromSubplotSpec(4, 1, subplot_spec=outer[2*i:2*(i+1), j], hspace=0.2, height_ratios=[1, 1, 1, 1])\n",
    "        current_ax = plt.Subplot(fig, inner[0])\n",
    "        current_ax.hist(q_repr_test[is_3b_test, i, j], bins=bins_range, label=\"bg 3b\", linewidth=1, histtype=\"step\", density=True, weights=weights_test[is_3b_test])\n",
    "        current_ax.hist(q_repr_test[is_bg4b_test, i, j], bins=bins_range, label=\"bg 4b\", linewidth=1, histtype=\"step\", density=True, weights=weights_test[is_bg4b_test])\n",
    "        current_ax.hist(q_repr_hh4b[:, i, j], bins=bins_range, label=\"HH 4b\", linewidth=1, histtype=\"step\", density=True, weights=weights_hh4b)\n",
    "        # calculate distance between two histograms (total variation distance)\n",
    "        # tvd = 0.5 * np.sum(np.abs(repr_hist_3b - repr_hist_4b))\n",
    "        current_ax.set_title(f\"View {j}, Feature {i}\")\n",
    "        # remove x labels\n",
    "        current_ax.set_xticks([])\n",
    "        current_ax.legend()\n",
    "        fig.add_subplot(current_ax)\n",
    "\n",
    "        current_ax = plt.Subplot(fig, inner[1])\n",
    "\n",
    "        current_ax.hist(q_repr_test[is_3b_test, i, j], bins=bins_range, label=\"bg 3b\", linewidth=1, histtype=\"step\", density=False, weights=weights_test[is_3b_test])\n",
    "        current_ax.hist(q_repr_test[is_bg4b_test, i, j], bins=bins_range, label=\"bg 4b\", linewidth=1, histtype=\"step\", density=False, weights=weights_test[is_bg4b_test])\n",
    "        current_ax.hist(q_repr_hh4b[:, i, j], bins=bins_range, label=\"HH 4b\", linewidth=1, histtype=\"step\", density=False, weights=weights_hh4b)\n",
    "        # calculate distance between two histograms (total variation distance)\n",
    "        # tvd = 0.5 * np.sum(np.abs(repr_hist_3b - repr_hist_4b))\n",
    "        # current_ax.set_title(f\"View {j}, Feature {i}\")\n",
    "        # remove x labels\n",
    "        current_ax.set_xticks([])\n",
    "        current_ax.legend()\n",
    "        fig.add_subplot(current_ax)\n",
    "\n",
    "        current_ax = plt.Subplot(fig, inner[2])\n",
    "        current_ax.hist(q_repr_test[is_3b_test, i, j], bins=bins_range, label=\"3b\", linewidth=1, histtype=\"step\", density=True, weights=weights_test[is_3b_test])\n",
    "        current_ax.hist(q_repr_test[is_4b_test, i, j], bins=bins_range, label=\"all 4b\", linewidth=1, histtype=\"step\", density=True, weights=weights_test[is_4b_test])\n",
    "        # calculate distance between two histograms (total variation distance)\n",
    "        # current_ax.set_title(f\"View {j}, Feature {i}, TV: {tvd:.2f}\")\n",
    "        # remove x labels\n",
    "        current_ax.set_xticks([])\n",
    "        current_ax.legend()\n",
    "\n",
    "        fig.add_subplot(current_ax)\n",
    "        current_ax = plt.Subplot(fig, inner[3])\n",
    "        current_ax.hist(q_repr_test[is_3b_test, i, j], bins=bins_range, label=\"3b\", linewidth=1, histtype=\"step\", density=False, weights=weights_test[is_3b_test])\n",
    "        current_ax.hist(q_repr_test[is_4b_test, i, j], bins=bins_range, label=\"all 4b\", linewidth=1, histtype=\"step\", density=False, weights=weights_test[is_4b_test])\n",
    "        # calculate distance between two histograms (total variation distance)\n",
    "        # current_ax.set_title(f\"View {j}, Feature {i}, TV: {tvd:.2f}\")\n",
    "        # remove x labels\n",
    "        current_ax.legend()\n",
    "        fig.add_subplot(current_ax)\n",
    "\n",
    "\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "bins_range = np.linspace(0, 1, 50)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(probs_4b_test[is_3b_test], bins=bins_range, label=\"bg 3b\", linewidth=1, histtype=\"step\", density=False, weights=weights_test[is_3b_test])\n",
    "ax.hist(probs_4b_test[is_bg4b_test], bins=bins_range, label=\"bg 4b\", linewidth=1, histtype=\"step\", density=False, weights=weights_test[is_bg4b_test])\n",
    "ax.hist(probs_4b_hh4b, bins=bins_range, label=\"HH 4b\", linewidth=1, histtype=\"step\", density=False, weights=weights_hh4b)\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"FvT output\")\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(probs_4b_test[is_3b_test], bins=bins_range, label=\"bg 3b\", linewidth=1, histtype=\"step\", density=False, weights=weights_test[is_3b_test])\n",
    "ax.hist(probs_4b_test[is_4b_test], bins=bins_range, label=\"all 4b\", linewidth=1, histtype=\"step\", density=False, weights=weights_test[is_4b_test])\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"FvT output\")\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-Fit Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# fit a classifier on q_repr_test to predict 4b vs 3b\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split the data\n",
    "(q_repr_refit_train, q_repr_refit_val, \n",
    " labels_4b_refit_train, labels_4b_refit_val, \n",
    " is_3b_refit_train, is_3b_refit_val, \n",
    " is_bg4b_refit_train, is_bg4b_refit_val, \n",
    " is_hh4b_refit_train, is_hh4b_refit_val,\n",
    " weights_refit_train, weights_refit_val) = train_test_split(q_repr_test, \n",
    "                                                            labels_4b_test, \n",
    "                                                            is_3b_test, \n",
    "                                                            is_bg4b_test, \n",
    "                                                            is_hh4b_test, \n",
    "                                                            weights_test, \n",
    "                                                            test_size=0.25, random_state=seed_)\n",
    "                                                                                         \n",
    "\n",
    "refit_clf = GradientBoostingClassifier(n_estimators=10, max_depth=3, learning_rate=0.1)\n",
    "refit_clf.fit(q_repr_refit_train.reshape(-1, 3*dim_quadjet_features), labels_4b_refit_train, sample_weight=weights_refit_train)\n",
    "\n",
    "refit_probs_val = refit_clf.predict_proba(q_repr_refit_val.reshape(-1, 3*dim_quadjet_features))[:, 1]\n",
    "refit_auc_val = roc_auc_score(labels_4b_refit_val, refit_probs_val)\n",
    "fpr, tpr, _ = roc_curve(labels_4b_refit_val, refit_probs_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(fpr, tpr, label=f\"ROC AUC: {refit_auc_val:.3f}\")\n",
    "ax.set_xlabel(\"FPR\")\n",
    "ax.set_ylabel(\"TPR\")\n",
    "ax.legend()\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "min_prob = refit_probs_val.min()\n",
    "max_prob = refit_probs_val.max()\n",
    "bins_range = np.linspace(min_prob, max_prob, 50)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(refit_probs_val[is_3b_refit_val], bins=bins_range, label=\"bg 3b\", linewidth=1, histtype=\"step\", density=False, weights=weights_refit_val[is_3b_refit_val])\n",
    "ax.hist(refit_probs_val[is_bg4b_refit_val], bins=bins_range, label=\"bg 4b\", linewidth=1, histtype=\"step\", density=False, weights=weights_refit_val[is_bg4b_refit_val])\n",
    "ax.hist(refit_probs_val[is_hh4b_refit_val], bins=bins_range, label=\"HH 4b\", linewidth=1, histtype=\"step\", density=False, weights=weights_refit_val[is_hh4b_refit_val])\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"FvT output\")\n",
    "plt.show()\n",
    "\n",
    "refit_probs_val_3b_hist, _ = np.histogram(refit_probs_val[is_3b_refit_val], bins=bins_range, density=False, weights=weights_refit_val[is_3b_refit_val])\n",
    "refit_probs_val_4b_hist, _ = np.histogram(refit_probs_val[~is_3b_refit_val], bins=bins_range, density=False, weights=weights_refit_val[~is_3b_refit_val])\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "refit_probs_val_hist_ratio = refit_probs_val_4b_hist / refit_probs_val_3b_hist \n",
    "ax.step(bins_range[:-1], refit_probs_val_hist_ratio, label=\"4b / 3b\", linewidth=1)\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"FvT output\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
