{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "features = [\n",
    "    \"sym_Jet0_pt\", \"sym_Jet1_pt\", \"sym_Jet2_pt\", \"sym_Jet3_pt\",\n",
    "    \"sym_Jet0_eta\", \"sym_Jet1_eta\", \"sym_Jet2_eta\", \"sym_Jet3_eta\",\n",
    "    \"sym_Jet0_phi\", \"sym_Jet1_phi\", \"sym_Jet2_phi\", \"sym_Jet3_phi\",  \n",
    "    \"sym_Jet0_m\", \"sym_Jet1_m\", \"sym_Jet2_m\", \"sym_Jet3_m\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from events_data import EventsData\n",
    "from dataset import SCDatasetInfo\n",
    "\n",
    "def plot_sr_stats(events, sr_stats, ax, label, **plot_kwargs):\n",
    "    assert len(events) == len(sr_stats)\n",
    "\n",
    "    sr_stats_argsort = np.argsort(sr_stats)[::-1]\n",
    "    weights = events.weights[sr_stats_argsort]\n",
    "    is_signal = events.is_signal[sr_stats_argsort]\n",
    "    is_4b = events.is_4b[sr_stats_argsort]\n",
    "\n",
    "    ax.plot(\n",
    "        np.cumsum(weights * is_4b) / np.sum(weights * is_4b),\n",
    "        np.cumsum(weights * is_signal) / np.sum(weights * is_signal),           \n",
    "        label=label,\n",
    "        **plot_kwargs,\n",
    "    )\n",
    "\n",
    "def get_is_signal(scdinfo: SCDatasetInfo, signal_filename: str):\n",
    "    # Now show the answer\n",
    "    is_signals = []\n",
    "    for file, file_len in zip(scdinfo.files, scdinfo.get_file_lengths()):\n",
    "        is_signals.append(\n",
    "            np.full(file_len, True)\n",
    "            if file.name == signal_filename\n",
    "            else np.full(file_len, False)\n",
    "        )\n",
    "    is_signal = np.concatenate(is_signals)\n",
    "    return is_signal\n",
    "\n",
    "\n",
    "\n",
    "def events_from_scdinfo(scdinfo: SCDatasetInfo, features: list, signal_filename: str):\n",
    "    df = scdinfo.fetch_data()\n",
    "    df[\"signal\"] = get_is_signal(scdinfo, signal_filename)\n",
    "    events = EventsData.from_dataframe(df, features)\n",
    "\n",
    "    return events\n",
    "\n",
    "def hist_events_by_labels(events: EventsData, bins, ax, **hist_kwargs):\n",
    "    ax.hist(events.fvt_score[events.is_3b], \n",
    "                        bins=bins, histtype=\"step\", label=\"3b\", \n",
    "                        weights=events.weights[events.is_3b], \n",
    "                        **hist_kwargs)\n",
    "    ax.hist(events.fvt_score[events.is_bg4b], \n",
    "                bins=bins, histtype=\"step\", label=\"bg4b\", \n",
    "                weights=events.weights[events.is_bg4b], \n",
    "                **hist_kwargs)\n",
    "    ax.hist(events.fvt_score[events.is_signal], \n",
    "                bins=bins, histtype=\"step\", label=\"signal\", \n",
    "                weights=events.weights[events.is_signal], \n",
    "                **hist_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from fvt_classifier import FvTClassifier\n",
    "from tst_info import TSTInfo\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "config_filename = \"configs/counting_test_v1_base.yml\"\n",
    "\n",
    "\n",
    "config = yaml.safe_load(open(config_filename, \"r\"))\n",
    "experiment_name = config[\"experiment_name\"]\n",
    "n_3b = config[\"n_3b\"]\n",
    "ratio_4b = config[\"ratio_4b\"]\n",
    "\n",
    "\n",
    "existing_hparams = TSTInfo.get_existing_hparams()\n",
    "seeds = np.unique([h[\"seed\"] for h in existing_hparams])\n",
    "signal_ratios = np.unique([h[\"signal_ratio\"] for h in existing_hparams])\n",
    "n_3bs = np.unique([h[\"n_3b\"] for h in existing_hparams])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[55, 60, 67]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argwhere([hp[\"n_3b\"] == 100_0000 for hp in existing_hparams]).flatten().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 69/201 [02:14<04:15,  1.94s/it]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "verbose = False\n",
    "show_plots = False\n",
    "hparam_filter = {\n",
    "    \"experiment_name\": experiment_name,\n",
    "    \"n_3b\": 100_000,\n",
    "}\n",
    "\n",
    "hashes = TSTInfo.find(hparam_filter)\n",
    "tst_results = []\n",
    "\n",
    "def permutation_test(stat_fn, is_4b, score, n_shuffles=1000, seed=None, direction=\"greater\"):\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    test_statistic = stat_fn(is_4b, score)\n",
    "    shuffled_test_statistic = np.zeros(n_shuffles)\n",
    "    for i in range(n_shuffles):\n",
    "        np.random.shuffle(is_4b)\n",
    "        shuffled_test_statistic[i] = stat_fn(is_4b, score)\n",
    "    \n",
    "    if direction == \"greater\":\n",
    "        p_value = np.mean(shuffled_test_statistic > test_statistic)\n",
    "    elif direction == \"less\":\n",
    "        p_value = np.mean(shuffled_test_statistic < test_statistic)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown direction: {direction}\")\n",
    "    return p_value\n",
    "\n",
    "for tstinfo_hash in tqdm.tqdm(hashes):\n",
    "    tstinfo = TSTInfo.load(tstinfo_hash)\n",
    "    signal_filename = tstinfo.hparams[\"signal_filename\"]\n",
    "    seed = tstinfo.hparams[\"seed\"]\n",
    "    signal_ratio = tstinfo.hparams[\"signal_ratio\"]        \n",
    "\n",
    "    scdinfo_tst = tstinfo.scdinfo_tst\n",
    "    events_tst = events_from_scdinfo(scdinfo_tst, features, signal_filename)\n",
    "    base_fvt_hash = tstinfo.base_fvt_tinfo_hash\n",
    "    fvt_model = FvTClassifier.load_from_checkpoint(f\"./checkpoints/{base_fvt_hash}_best.ckpt\")\n",
    "    fvt_model.eval()\n",
    "    events_tst.set_model_scores(fvt_model)\n",
    "    CR_fvt_hash = tstinfo.CR_fvt_tinfo_hash\n",
    "    CR_model = FvTClassifier.load_from_checkpoint(f\"./checkpoints/{CR_fvt_hash}_best.ckpt\")\n",
    "    CR_model.eval()\n",
    "\n",
    "\n",
    "    SR_stats = tstinfo.SR_stats\n",
    "    SR_cut = tstinfo.SR_cut\n",
    "    CR_cut = tstinfo.CR_cut\n",
    "    in_SR = SR_stats >= SR_cut\n",
    "    in_CR = (SR_stats < SR_cut) & (SR_stats >= CR_cut)\n",
    "\n",
    "    weights_4b = events_tst.weights * events_tst.is_4b\n",
    "    weights_signal = events_tst.weights * events_tst.is_signal\n",
    "    \n",
    "    ratio_4b = tstinfo.hparams[\"ratio_4b\"]\n",
    "    probs_4b_est = CR_model.predict(events_tst.X_torch).detach().cpu().numpy()[:, 1]\n",
    "    reweights = ratio_4b * probs_4b_est / ((1 - ratio_4b) * (1 - probs_4b_est))\n",
    "    events_tst.reweight(\n",
    "        np.where(events_tst.is_4b, events_tst.weights, events_tst.weights * reweights))\n",
    "    events_tst_SR = events_tst[in_SR]\n",
    "\n",
    "    n_samples = 1000\n",
    "    fvt_cut = np.mean(events_tst.fvt_score) + np.std(events_tst.fvt_score)\n",
    "    tst_samples = events_tst[in_SR & (events_tst.fvt_score > fvt_cut)].poisson_sample(n_samples, seed=seed)\n",
    "\n",
    "    is_4b = tst_samples.is_4b\n",
    "    fvt_score = tst_samples.fvt_score\n",
    "\n",
    "    def fvt_test_statistic(is_4b, score):\n",
    "        # return np.abs(np.mean(score[is_4b]) - np.mean(score[~is_4b]))\n",
    "        return np.mean(score[is_4b]) - np.mean(score[~is_4b])\n",
    "    def binary_test_statistic(is_4b, score):\n",
    "        return np.mean(score[is_4b] > fvt_cut)\n",
    "    \n",
    "    fvt_p_value = permutation_test(fvt_test_statistic, is_4b, fvt_score, seed=seed, direction=\"greater\")\n",
    "    # binary_p_value = permutation_test(binary_test_statistic, is_4b, fvt_score, seed=seed, direction=\"greater\")\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"seed: {seed}, signal_ratio: {signal_ratio}\")\n",
    "        print(\"4b, signal in SR: \", np.sum(weights_4b[in_SR]) / np.sum(weights_4b), \n",
    "            np.sum(weights_signal[in_SR]) / np.sum(weights_signal))\n",
    "        print(\"4b, signal in CR: \", np.sum(weights_4b[in_CR]) / np.sum(weights_4b),\n",
    "                np.sum(weights_signal[in_CR]) / np.sum(weights_signal))\n",
    "\n",
    "        print(f\"FvT p-value: {fvt_p_value}\")\n",
    "        print(f\"FvT rejected: {fvt_p_value < 0.05}\")\n",
    "        # print(f\"FvT p-value: {fvt_p_value}, binary p-value: {binary_p_value}\")\n",
    "        # print(f\"FvT rejected: {fvt_p_value < 0.05}, binary rejected: {binary_p_value < 0.05}\")\n",
    "\n",
    "    if show_plots:\n",
    "        # bins = np.linspace(0, 1, 30)\n",
    "        min_score = np.min(events_tst.fvt_score)\n",
    "        max_score = np.max(events_tst.fvt_score)\n",
    "        bins = np.linspace(min_score, max_score, 20)\n",
    "        \n",
    "        fig = plt.figure(figsize=(10, 5))\n",
    "        gs = GridSpec(3, 1, figure=fig)\n",
    "        ax1 = fig.add_subplot(gs[0:2])\n",
    "        hist_events_by_labels(events_tst_SR, bins, ax1)\n",
    "        ax1.axvline(fvt_cut, color=\"black\", linestyle=\"--\")\n",
    "        ax1.set_yscale(\"log\")\n",
    "        ax1.set_xlim(min_score - 0.05, max_score + 0.05)\n",
    "        ax1.set_xlabel(\"FvT score\")\n",
    "        ax1.set_ylabel(\"Events\")\n",
    "        ax1.legend()\n",
    "\n",
    "        hist_3b, _ = np.histogram(events_tst_SR.fvt_score[events_tst_SR.is_3b], bins=bins, \n",
    "                                  weights=events_tst_SR.weights[events_tst_SR.is_3b])\n",
    "        hist_bg4b, _ = np.histogram(events_tst_SR.fvt_score[events_tst_SR.is_bg4b], bins=bins, \n",
    "                                    weights=events_tst_SR.weights[events_tst_SR.is_bg4b])\n",
    "        hist_signal, _ = np.histogram(events_tst_SR.fvt_score[events_tst_SR.is_signal], bins=bins, \n",
    "                                    weights=events_tst_SR.weights[events_tst_SR.is_signal])\n",
    "\n",
    "        ratio_3b_bg4b = hist_3b / hist_bg4b\n",
    "        ratio_3b_bg4b[np.isnan(ratio_3b_bg4b)] = 0\n",
    "        midpoints = (bins[1:] + bins[:-1]) / 2\n",
    "        ax2 = fig.add_subplot(gs[2])\n",
    "        ax2.errorbar(midpoints, \n",
    "                     ratio_3b_bg4b, \n",
    "                     yerr=np.sqrt(1 / hist_3b + 1 / hist_bg4b) * (hist_3b / hist_bg4b), \n",
    "                     label=\"3b/bg4b\")\n",
    "        ax2.set_xlabel(\"FvT score\")\n",
    "        ax2.set_ylabel(\"3b/bg4b\")\n",
    "        ax2.set_ylim(0.5, 1.5)\n",
    "        ax2.set_xlim(min_score - 0.05, max_score + 0.05)\n",
    "        ax2.axhline(1, color=\"black\")\n",
    "        plt.show()\n",
    "\n",
    "    tst_results.append({\n",
    "        \"seed\": seed,\n",
    "        \"signal_ratio\": signal_ratio,\n",
    "        \"fvt\": {\n",
    "            \"p_value\": fvt_p_value,\n",
    "            \"rejected\": fvt_p_value < 0.05,\n",
    "        },\n",
    "        # \"binary\": {\n",
    "        #     \"p_value\": binary_p_value,\n",
    "        #     \"rejected\": binary_p_value < 0.05,\n",
    "        #     \"fvt_cut\": fvt_cut,\n",
    "        # }\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_results_fvt_df = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"seed\": r[\"seed\"],\n",
    "            \"signal_ratio\": r[\"signal_ratio\"],\n",
    "            \"p_value\": r[\"fvt\"][\"p_value\"],\n",
    "            \"rejected\": r[\"fvt\"][\"rejected\"],\n",
    "        }\n",
    "        for r in tst_results\n",
    "    ]\n",
    ")\n",
    "\n",
    "# tst_results_binary_df = pd.DataFrame(\n",
    "#     [\n",
    "#         {\n",
    "#             \"seed\": r[\"seed\"],\n",
    "#             \"signal_ratio\": r[\"signal_ratio\"],\n",
    "#             \"p_value\": r[\"binary\"][\"p_value\"],\n",
    "#             \"rejected\": r[\"binary\"][\"rejected\"],\n",
    "#         }\n",
    "#         for r in tst_results\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seed</th>\n",
       "      <th>p_value</th>\n",
       "      <th>rejected</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>signal_ratio</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.00</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6015</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.01</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4750</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.02</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              seed  p_value  rejected\n",
       "signal_ratio                         \n",
       "0.00           0.5   0.6015       0.0\n",
       "0.01           0.5   0.4750       0.5\n",
       "0.02           0.5   0.0000       1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(tst_results_fvt_df.groupby([\"signal_ratio\"]).mean())\n",
    "# display(tst_results_binary_df.groupby([\"signal_ratio\"]).mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
