{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "current_pwd = os.getcwd()\n",
    "\n",
    "possible_paths = [\n",
    "    '/home/export/soheuny/SRFinder/soheun/notebooks', \n",
    "    '/home/soheuny/HH4bsim/soheun/notebooks'\n",
    "]\n",
    "    \n",
    "assert os.getcwd() in possible_paths, f\"Did you change the path? It should be one of {possible_paths}\"\n",
    "os.chdir(\"..\")\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import torch\n",
    "\n",
    "from plots import hist_events_by_labels\n",
    "from events_data import EventsData\n",
    "from fvt_classifier import FvTClassifier\n",
    "\n",
    "\n",
    "features = [\n",
    "    \"sym_Jet0_pt\", \"sym_Jet1_pt\", \"sym_Jet2_pt\", \"sym_Jet3_pt\",\n",
    "    \"sym_Jet0_eta\", \"sym_Jet1_eta\", \"sym_Jet2_eta\", \"sym_Jet3_eta\",\n",
    "    \"sym_Jet0_phi\", \"sym_Jet1_phi\", \"sym_Jet2_phi\", \"sym_Jet3_phi\",  \n",
    "    \"sym_Jet0_m\", \"sym_Jet1_m\", \"sym_Jet2_m\", \"sym_Jet3_m\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from events_data import events_from_scdinfo\n",
    "from tst_info import TSTInfo\n",
    "from debiasing import get_bias_fn, get_histograms\n",
    "from plots import hist_events_by_labels\n",
    "import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist_and_ratio(tstinfo: TSTInfo, \n",
    "                    x_values: np.ndarray, \n",
    "                    events_tst_clone: EventsData, \n",
    "                    in_CR: np.ndarray, \n",
    "                    in_SR: np.ndarray, \n",
    "                    nbins: int = 10,\n",
    "                    bins_mode: str = \"quantile\",\n",
    "                    ylim: tuple[float, float] = (0.5, 1.5), \n",
    "                    xlabel: str = None,\n",
    "                    yscale: str = \"linear\"):\n",
    "    assert len(x_values) == len(events_tst_clone)\n",
    "    \n",
    "    if bins_mode == \"quantile\":\n",
    "        bins_CR = np.quantile(x_values[in_CR], np.linspace(0, 1, nbins))\n",
    "        bins_SR = np.quantile(x_values[in_SR], np.linspace(0, 1, nbins))\n",
    "    else:\n",
    "        bins_CR = np.linspace(np.min(x_values[in_CR]), np.max(x_values[in_CR]), nbins)\n",
    "        bins_SR = np.linspace(np.min(x_values[in_SR]), np.max(x_values[in_SR]), nbins)\n",
    "        \n",
    "\n",
    "    gs = GridSpec(3, 2)\n",
    "    fig = plt.figure(figsize=(15, 7))\n",
    "    fig.suptitle(f\"seed={tstinfo.hparams['seed']}, signal_ratio={tstinfo.hparams['signal_ratio']}\")\n",
    "    fig.supxlabel(xlabel)\n",
    "    \n",
    "    tst_fvt_scores_CR = x_values[in_CR]\n",
    "    events_tst_clone_CR = events_tst_clone[in_CR]\n",
    "\n",
    "    \n",
    "    hist_4b_CR, _ = np.histogram(tst_fvt_scores_CR[events_tst_clone_CR.is_4b], \n",
    "                                    bins=bins_CR, \n",
    "                                    weights=events_tst_clone_CR.weights[events_tst_clone_CR.is_4b])\n",
    "    \n",
    "    hist_3b_CR, _ = np.histogram(tst_fvt_scores_CR[~events_tst_clone_CR.is_4b], \n",
    "                                    bins=bins_CR, \n",
    "                                    weights=events_tst_clone_CR.weights[~events_tst_clone_CR.is_4b])\n",
    "    \n",
    "    \n",
    "    ax = fig.add_subplot(gs[:2, 0])\n",
    "    ax.set_title(\"Control Region\")\n",
    "    ax.stairs(hist_3b_CR, bins_CR, label=\"3b\")\n",
    "    ax.stairs(hist_4b_CR, bins_CR, label=\"4b\")\n",
    "    ax.set_yscale(yscale)\n",
    "    ax.legend()\n",
    "    \n",
    "    ax = fig.add_subplot(gs[2, 0])\n",
    "    ax.errorbar((bins_CR[1:] + bins_CR[:-1]) / 2, hist_4b_CR / hist_3b_CR, \n",
    "                yerr=np.sqrt(hist_4b_CR) / hist_3b_CR, \n",
    "                fmt=\"o\", markersize=3, label=\"4b / 3b\", capsize=3)\n",
    "    ax.set_ylim(ylim)\n",
    "    ax.set_yticks(np.arange(ylim[0], ylim[1] + 0.1, 0.1))  # Set y ticks from 0.5 to 1.5 with interval 0.1\n",
    "    ax.set_yticklabels([ylim[0]] + [None] * 4 + [(ylim[0] + ylim[1]) / 2] + [None] * 4 + [ylim[1]])\n",
    "    \n",
    "    ax.set_ylabel(\"True 4b / Modeled 4b\")\n",
    "    ax.hlines(1, bins_CR[0], bins_CR[-1], color=\"black\", linestyle=\"--\")\n",
    "    ymin, ymax = ax.get_ylim()\n",
    "    ax.vlines(bins_CR[1:-1], ymin, ymax, color=\"black\", linestyle=\"--\", alpha=0.5)\n",
    "    \n",
    "    # get histogram of 4b, 3b in SR\n",
    "    tst_fvt_scores_SR = x_values[in_SR]\n",
    "    events_tst_clone_SR = events_tst_clone[in_SR]\n",
    "\n",
    "    \n",
    "    hist_4b_SR, _ = np.histogram(tst_fvt_scores_SR[events_tst_clone_SR.is_4b], \n",
    "                                    bins=bins_SR, \n",
    "                                    weights=events_tst_clone_SR.weights[events_tst_clone_SR.is_4b])\n",
    "    \n",
    "    hist_3b_SR, _ = np.histogram(tst_fvt_scores_SR[~events_tst_clone_SR.is_4b], \n",
    "                                    bins=bins_SR, \n",
    "                                    weights=events_tst_clone_SR.weights[~events_tst_clone_SR.is_4b])\n",
    "    \n",
    "    ax = fig.add_subplot(gs[:2, 1])\n",
    "    ax.set_title(\"Signal Region\")\n",
    "    ax.stairs(hist_3b_SR, bins_SR, label=\"3b\")\n",
    "    ax.stairs(hist_4b_SR, bins_SR, label=\"4b\")\n",
    "    ax.set_yscale(yscale)\n",
    "    ax.legend()\n",
    "    \n",
    "    ax = fig.add_subplot(gs[2, 1])\n",
    "    ax.errorbar((bins_SR[1:] + bins_SR[:-1]) / 2, hist_4b_SR / hist_3b_SR, \n",
    "                yerr=np.sqrt(hist_4b_SR) / hist_3b_SR, \n",
    "                fmt=\"o\", markersize=3, label=\"4b / 3b\", capsize=3)\n",
    "    ax.set_ylim(ylim)\n",
    "    ax.set_yticks(np.arange(ylim[0], ylim[1] + 0.1, 0.1))  # Set y ticks from 0.5 to 1.5 with interval 0.1\n",
    "    ax.set_yticklabels([ylim[0]] + [None] * 4 + [(ylim[0] + ylim[1]) / 2] + [None] * 4 + [ylim[1]])\n",
    "    \n",
    "    ax.set_ylabel(\"True 4b / Modeled 4b\")\n",
    "    ax.hlines(1, bins_SR[0], bins_SR[-1], color=\"black\", linestyle=\"--\")\n",
    "    ymin, ymax = ax.get_ylim()\n",
    "    ax.vlines(bins_SR[1:-1], ymin, ymax, color=\"black\", linestyle=\"--\", alpha=0.5)\n",
    "    \n",
    "    # plt.show()\n",
    "    # plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_reweighted_samples(events_reweighted: EventsData, \n",
    "                            events_not_reweighted: EventsData,\n",
    "                            hist_values: np.ndarray, \n",
    "                            fig: plt.Figure):\n",
    "    gs = GridSpec(2, 2, figure=fig)\n",
    "    for ax_cnt, quantile in enumerate([True, False]):\n",
    "        if quantile:\n",
    "            q = np.linspace(0, 1, 10)\n",
    "            bins = np.quantile(hist_values, q)\n",
    "        else:\n",
    "            bins = np.linspace(np.min(hist_values), np.max(hist_values), 10)\n",
    "\n",
    "        ax = fig.add_subplot(gs[ax_cnt, 0])\n",
    "        hist_events_by_labels(events_reweighted, hist_values, bins=bins, ax=ax)\n",
    "        ax.set_title(\"Reweighted\")\n",
    "        ax.legend()\n",
    "        ax = fig.add_subplot(gs[ax_cnt, 1])\n",
    "        hist_events_by_labels(events_not_reweighted, hist_values, bins=bins, ax=ax)\n",
    "        ax.set_title(\"NOT Reweighted\")\n",
    "        ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "import numpy as np\n",
    "\n",
    "def auc_score(\n",
    "    clf_scores: np.ndarray, \n",
    "    is_4b: np.ndarray,\n",
    "    weights: np.ndarray = None):\n",
    "    \n",
    "    if weights is None:\n",
    "        weights = np.ones_like(clf_scores)\n",
    "    \n",
    "    assert len(clf_scores) == len(is_4b) == len(weights)\n",
    "    \n",
    "    clf_scores_3b = clf_scores[~is_4b].reshape(-1, 1)\n",
    "    clf_scores_4b = clf_scores[is_4b].reshape(1, -1)\n",
    "    weights_3b = weights[~is_4b].reshape(-1, 1)\n",
    "    weights_4b = weights[is_4b].reshape(1, -1)\n",
    "    \n",
    "    score_diff = clf_scores_4b - clf_scores_3b\n",
    "    weights = weights_3b * weights_4b\n",
    "    \n",
    "    return np.sum(weights * (score_diff > 0)) / np.sum(weights)\n",
    "\n",
    "def mce_score_fn(pi: float = 0.5):\n",
    "    \n",
    "    def mce_score_inner(\n",
    "        clf_scores: np.ndarray, \n",
    "        is_4b: np.ndarray,\n",
    "        weights: np.ndarray = None):\n",
    "    \n",
    "        if weights is None:\n",
    "            weights = np.ones_like(clf_scores)\n",
    "        \n",
    "        assert len(clf_scores) == len(is_4b) == len(weights)\n",
    "        \n",
    "        clf_scores_3b = clf_scores[~is_4b]\n",
    "        clf_scores_4b = clf_scores[is_4b]\n",
    "        weights_3b = weights[~is_4b]\n",
    "        weights_4b = weights[is_4b]\n",
    "        \n",
    "        return 0.5 * (np.sum(weights_3b * (clf_scores_3b > pi)) / np.sum(weights_3b) + \n",
    "                    np.sum(weights_4b * (clf_scores_4b < pi)) / np.sum(weights_4b))\n",
    "        \n",
    "    return mce_score_inner\n",
    "    \n",
    "    \n",
    "def test_via_classifier(clf_scores: np.ndarray, is_4b: np.ndarray, weights: np.ndarray, \n",
    "                score_func: Callable[[np.ndarray, np.ndarray, np.ndarray], float],\n",
    "                bootstrap: bool = True,\n",
    "                n_samples: int = 1000, \n",
    "                p_value_type: str = \"greater\", \n",
    "                do_tqdm: bool = True):\n",
    "\n",
    "    \n",
    "    assert len(clf_scores) == len(is_4b) == len(weights)\n",
    "    assert p_value_type in [\"greater\", \"less\", \"two-sided\"], f\"p_value_type {p_value_type} is not supported\"\n",
    "    \n",
    "    score_0 = score_func(clf_scores, is_4b, weights)\n",
    "    \n",
    "    null_scores = []\n",
    "    for _ in tqdm.tqdm(range(n_samples), disable=not do_tqdm):\n",
    "        if bootstrap:\n",
    "            indices = np.random.choice(len(clf_scores), len(clf_scores), replace=True)\n",
    "        else:\n",
    "            indices = np.arange(len(clf_scores))\n",
    "            \n",
    "        clf_scores_rnd = clf_scores[indices]\n",
    "        weights_rnd = weights[indices]\n",
    "        is_4b_rnd = np.random.choice(len(clf_scores), np.sum(is_4b), replace=False)\n",
    "        is_4b_rnd = np.isin(np.arange(len(clf_scores)), is_4b_rnd)\n",
    "            \n",
    "        null_scores.append(score_func(clf_scores_rnd, is_4b_rnd, weights_rnd))\n",
    "\n",
    "    if p_value_type == \"greater\":\n",
    "        p_value = np.mean(null_scores > score_0)\n",
    "    elif p_value_type == \"less\":\n",
    "        p_value = np.mean(null_scores < score_0)\n",
    "    elif p_value_type == \"two-sided\":\n",
    "        p_value = np.mean(np.abs(null_scores - score_0) > np.abs(score_0))\n",
    "    \n",
    "    return score_0, null_scores, p_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.unique([h[\"experiment_name\"] for h in TSTInfo.get_existing_hparams()])\n",
    "\n",
    "hashes = TSTInfo.find(hparam_filter={\"experiment_name\": \"counting_test_high_4b_in_CR\", \"n_3b\": 1_400_000}, \n",
    "                      sort_by=[\"seed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_3b=1400000, signal_ratio=0.0, seed=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/export/soheuny/.conda/envs/coffea_torch/lib/python3.11/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/export/soheuny/.conda/envs/coffea_torch/lib/py ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [5]\n",
      "\n",
      "  | Name     | Type       | Params\n",
      "----------------------------------------\n",
      "0 | encoder  | FvTEncoder | 920   \n",
      "1 | select_q | conv1d     | 8     \n",
      "2 | out      | conv1d     | 16    \n",
      "----------------------------------------\n",
      "895       Trainable params\n",
      "49        Non-trainable params\n",
      "944       Total params\n",
      "0.004     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 85/85 [00:05<00:00, 16.18it/s, v_num=800, val_loss=0.694, train_loss=0.693]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 85/85 [00:05<00:00, 16.07it/s, v_num=800, val_loss=0.694, train_loss=0.693]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:46<00:00,  9.41it/s]\n",
      "100%|██████████| 1000/1000 [01:47<00:00,  9.34it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 1335.42it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 1534.73it/s]\n",
      "/tmp/ipykernel_52854/1734614572.py:152: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, pd.DataFrame([results])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_3b=1400000, signal_ratio=0.01, seed=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/export/soheuny/.conda/envs/coffea_torch/lib/python3.11/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/export/soheuny/.conda/envs/coffea_torch/lib/py ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [5]\n",
      "\n",
      "  | Name     | Type       | Params\n",
      "----------------------------------------\n",
      "0 | encoder  | FvTEncoder | 920   \n",
      "1 | select_q | conv1d     | 8     \n",
      "2 | out      | conv1d     | 16    \n",
      "----------------------------------------\n",
      "895       Trainable params\n",
      "49        Non-trainable params\n",
      "944       Total params\n",
      "0.004     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 80/80 [00:05<00:00, 15.51it/s, v_num=801, val_loss=0.693, train_loss=0.693]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 80/80 [00:05<00:00, 15.40it/s, v_num=801, val_loss=0.693, train_loss=0.693]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:53<00:00,  8.78it/s]\n",
      "100%|██████████| 1000/1000 [01:53<00:00,  8.83it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 1437.10it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 1639.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_3b=1400000, signal_ratio=0.02, seed=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/export/soheuny/.conda/envs/coffea_torch/lib/python3.11/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/export/soheuny/.conda/envs/coffea_torch/lib/py ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [5]\n",
      "\n",
      "  | Name     | Type       | Params\n",
      "----------------------------------------\n",
      "0 | encoder  | FvTEncoder | 920   \n",
      "1 | select_q | conv1d     | 8     \n",
      "2 | out      | conv1d     | 16    \n",
      "----------------------------------------\n",
      "895       Trainable params\n",
      "49        Non-trainable params\n",
      "944       Total params\n",
      "0.004     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 76/76 [00:04<00:00, 16.27it/s, v_num=802, val_loss=0.686, train_loss=0.686]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 76/76 [00:04<00:00, 16.15it/s, v_num=802, val_loss=0.686, train_loss=0.686]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:39<00:00, 10.00it/s]\n",
      "100%|██████████| 1000/1000 [01:40<00:00,  9.95it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 1467.28it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 1707.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_3b=1400000, signal_ratio=0.0, seed=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/export/soheuny/.conda/envs/coffea_torch/lib/python3.11/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/export/soheuny/.conda/envs/coffea_torch/lib/py ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [5]\n",
      "\n",
      "  | Name     | Type       | Params\n",
      "----------------------------------------\n",
      "0 | encoder  | FvTEncoder | 920   \n",
      "1 | select_q | conv1d     | 8     \n",
      "2 | out      | conv1d     | 16    \n",
      "----------------------------------------\n",
      "895       Trainable params\n",
      "49        Non-trainable params\n",
      "944       Total params\n",
      "0.004     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 78/78 [00:04<00:00, 17.56it/s, v_num=803, val_loss=0.693, train_loss=0.693]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 78/78 [00:04<00:00, 17.43it/s, v_num=803, val_loss=0.693, train_loss=0.693]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:45<00:00,  9.47it/s]\n",
      "100%|██████████| 1000/1000 [01:45<00:00,  9.46it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 1409.71it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 1632.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_3b=1400000, signal_ratio=0.01, seed=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/export/soheuny/.conda/envs/coffea_torch/lib/python3.11/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/export/soheuny/.conda/envs/coffea_torch/lib/py ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [5]\n",
      "\n",
      "  | Name     | Type       | Params\n",
      "----------------------------------------\n",
      "0 | encoder  | FvTEncoder | 920   \n",
      "1 | select_q | conv1d     | 8     \n",
      "2 | out      | conv1d     | 16    \n",
      "----------------------------------------\n",
      "895       Trainable params\n",
      "49        Non-trainable params\n",
      "944       Total params\n",
      "0.004     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 75/75 [00:04<00:00, 16.02it/s, v_num=804, val_loss=0.693, train_loss=0.693]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 75/75 [00:04<00:00, 15.90it/s, v_num=804, val_loss=0.693, train_loss=0.693]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:19<00:00, 12.65it/s]\n",
      "100%|██████████| 1000/1000 [01:18<00:00, 12.70it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 1497.70it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 1770.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_3b=1400000, signal_ratio=0.02, seed=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/export/soheuny/.conda/envs/coffea_torch/lib/python3.11/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/export/soheuny/.conda/envs/coffea_torch/lib/py ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [5]\n",
      "\n",
      "  | Name     | Type       | Params\n",
      "----------------------------------------\n",
      "0 | encoder  | FvTEncoder | 920   \n",
      "1 | select_q | conv1d     | 8     \n",
      "2 | out      | conv1d     | 16    \n",
      "----------------------------------------\n",
      "895       Trainable params\n",
      "49        Non-trainable params\n",
      "944       Total params\n",
      "0.004     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 73/73 [00:04<00:00, 16.25it/s, v_num=805, val_loss=0.691, train_loss=0.692]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 73/73 [00:04<00:00, 16.13it/s, v_num=805, val_loss=0.691, train_loss=0.692]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:35<00:00, 10.48it/s]\n",
      "100%|██████████| 1000/1000 [01:34<00:00, 10.59it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 1521.60it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 1814.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_3b=1400000, signal_ratio=0.0, seed=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/export/soheuny/.conda/envs/coffea_torch/lib/python3.11/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/export/soheuny/.conda/envs/coffea_torch/lib/py ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [5]\n",
      "\n",
      "  | Name     | Type       | Params\n",
      "----------------------------------------\n",
      "0 | encoder  | FvTEncoder | 920   \n",
      "1 | select_q | conv1d     | 8     \n",
      "2 | out      | conv1d     | 16    \n",
      "----------------------------------------\n",
      "895       Trainable params\n",
      "49        Non-trainable params\n",
      "944       Total params\n",
      "0.004     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 81/81 [00:04<00:00, 16.82it/s, v_num=806, val_loss=0.693, train_loss=0.693]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 81/81 [00:04<00:00, 16.71it/s, v_num=806, val_loss=0.693, train_loss=0.693]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 973/1000 [01:30<00:02, 10.74it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 105\u001b[0m\n\u001b[1;32m    101\u001b[0m mce_score \u001b[38;5;241m=\u001b[39m mce_score_fn(pi\u001b[38;5;241m=\u001b[39mpi)\n\u001b[1;32m    103\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[0;32m--> 105\u001b[0m auc_score_0, null_auc_scores_bootstrap, p_value_auc_bootstrap \u001b[38;5;241m=\u001b[39m \u001b[43mtest_via_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSR_classifier_scores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m                                                                                  \u001b[49m\u001b[43mevents_tst_SR_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_4b\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m                                                                                  \u001b[49m\u001b[43mevents_tst_SR_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m                                                                                  \u001b[49m\u001b[43mauc_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m                                                                                  \u001b[49m\u001b[43mbootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m                                                                                  \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m                                                                                  \u001b[49m\u001b[43mp_value_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgreater\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m                                                                                  \u001b[49m\u001b[43mdo_tqdm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_tqdm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m auc_score_0, null_auc_scores_permutation, p_value_auc_permutation \u001b[38;5;241m=\u001b[39m test_via_classifier(SR_classifier_scores, \n\u001b[1;32m    114\u001b[0m                                                                                   events_tst_SR_test\u001b[38;5;241m.\u001b[39mis_4b, \n\u001b[1;32m    115\u001b[0m                                                                                   events_tst_SR_test\u001b[38;5;241m.\u001b[39mweights, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    119\u001b[0m                                                                                   p_value_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgreater\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m    120\u001b[0m                                                                                   do_tqdm\u001b[38;5;241m=\u001b[39mdo_tqdm)\n\u001b[1;32m    121\u001b[0m mce_score_0, null_mce_scores_bootstrap, p_value_mce_bootstrap \u001b[38;5;241m=\u001b[39m test_via_classifier(SR_classifier_scores, \n\u001b[1;32m    122\u001b[0m                                                                                   events_tst_SR_test\u001b[38;5;241m.\u001b[39mis_4b, \n\u001b[1;32m    123\u001b[0m                                                                                   events_tst_SR_test\u001b[38;5;241m.\u001b[39mweights, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    127\u001b[0m                                                                                   p_value_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mless\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m    128\u001b[0m                                                                                   do_tqdm\u001b[38;5;241m=\u001b[39mdo_tqdm)\n",
      "Cell \u001b[0;32mIn[5], line 72\u001b[0m, in \u001b[0;36mtest_via_classifier\u001b[0;34m(clf_scores, is_4b, weights, score_func, bootstrap, n_samples, p_value_type, do_tqdm)\u001b[0m\n\u001b[1;32m     69\u001b[0m     is_4b_rnd \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;28mlen\u001b[39m(clf_scores), np\u001b[38;5;241m.\u001b[39msum(is_4b), replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     70\u001b[0m     is_4b_rnd \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39misin(np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(clf_scores)), is_4b_rnd)\n\u001b[0;32m---> 72\u001b[0m     null_scores\u001b[38;5;241m.\u001b[39mappend(\u001b[43mscore_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclf_scores_rnd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_4b_rnd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_rnd\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p_value_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgreater\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     75\u001b[0m     p_value \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(null_scores \u001b[38;5;241m>\u001b[39m score_0)\n",
      "Cell \u001b[0;32mIn[5], line 22\u001b[0m, in \u001b[0;36mauc_score\u001b[0;34m(clf_scores, is_4b, weights)\u001b[0m\n\u001b[1;32m     19\u001b[0m score_diff \u001b[38;5;241m=\u001b[39m clf_scores_4b \u001b[38;5;241m-\u001b[39m clf_scores_3b\n\u001b[1;32m     20\u001b[0m weights \u001b[38;5;241m=\u001b[39m weights_3b \u001b[38;5;241m*\u001b[39m weights_4b\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39msum(weights \u001b[38;5;241m*\u001b[39m (score_diff \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)) \u001b[38;5;241m/\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/coffea_torch/lib/python3.11/site-packages/numpy/core/fromnumeric.py:2313\u001b[0m, in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2310\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[1;32m   2311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n\u001b[0;32m-> 2313\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2314\u001b[0m \u001b[43m                      \u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/coffea_torch/lib/python3.11/site-packages/numpy/core/fromnumeric.py:88\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     86\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[0;32m---> 88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mufunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpasskwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from training_info import TrainingInfoV2\n",
    "from plots import calibration_plot\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from ancillary_features import get_m4j\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import pandas as pd\n",
    "\n",
    "n_3b = 140_0000\n",
    "device = torch.device(\"cuda\")\n",
    "experiment_name = \"counting_test_high_4b_in_CR\"\n",
    "signal_filename = \"HH4b_picoAOD.h5\"\n",
    "ratio_4b = 0.5\n",
    "batch_size = 1024\n",
    "hparam_filter = {\n",
    "    \"experiment_name\": lambda x: x in [experiment_name],\n",
    "    \"n_3b\": n_3b,\n",
    "    \"seed\": lambda x: x < 10,\n",
    "}\n",
    "do_tqdm = True\n",
    "\n",
    "hashes = TSTInfo.find(hparam_filter, sort_by=[\"signal_ratio\", \"seed\"])\n",
    "\n",
    "df_name = f\"data/tsv/tst_results_summary_{experiment_name}_n_3b={n_3b}_mi_test.tsv\"\n",
    "if os.path.exists(df_name):\n",
    "    df = pd.read_csv(df_name, sep=\"\\t\")\n",
    "else:\n",
    "    df = pd.DataFrame(columns=[\"tstinfo_hash\", \"seed\", \"signal_ratio\", \n",
    "                               \"auc_score_0\", \"p_value_auc_bootstrap\", \"p_value_auc_permutation\", \n",
    "                               \"mce_score_0\", \"p_value_mce_bootstrap\", \"p_value_mce_permutation\", \n",
    "                               ])\n",
    "    \n",
    "\n",
    "for tstinfo_hash in hashes:\n",
    "    tstinfo = TSTInfo.load(tstinfo_hash)\n",
    "    print(f\"n_3b={tstinfo.hparams['n_3b']}, signal_ratio={tstinfo.hparams['signal_ratio']}, seed={tstinfo.hparams['seed']}\")\n",
    "    \n",
    "    if tstinfo_hash in df[\"tstinfo_hash\"].values:\n",
    "        continue\n",
    "    \n",
    "    CR_fvt_tinfo_hash = tstinfo.CR_fvt_tinfo_hash\n",
    "    CR_fvt_tinfo = TrainingInfoV2.load(CR_fvt_tinfo_hash)\n",
    "    CR_model = FvTClassifier.load_from_checkpoint(f\"data/checkpoints/{CR_fvt_tinfo.hash}_best.ckpt\")\n",
    "    CR_model.to(device)\n",
    "    CR_model.eval()\n",
    "    \n",
    "    train_scdinfo, val_scdinfo = CR_fvt_tinfo.fetch_train_val_scdinfo()\n",
    "    events_train = events_from_scdinfo(train_scdinfo, features, signal_filename)\n",
    "    events_val = events_from_scdinfo(val_scdinfo, features, signal_filename)\n",
    "    events_tst = events_from_scdinfo(tstinfo.scdinfo_tst, features, signal_filename)\n",
    "    \n",
    "    tst_fvt_scores = CR_model.predict(events_tst.X_torch).detach().cpu().numpy()[:, 1]\n",
    "    SR_stat = tstinfo.SR_stats\n",
    "    reweights = tst_fvt_scores / (1 - tst_fvt_scores) * (ratio_4b / (1 - ratio_4b))\n",
    "    SR_cut = tstinfo.SR_cut\n",
    "    CR_cut = tstinfo.CR_cut\n",
    "    \n",
    "    in_SR = SR_stat > SR_cut\n",
    "    \n",
    "    events_tst_clone = events_tst.clone()\n",
    "    events_tst_clone.reweight(np.where(events_tst_clone.is_4b, \n",
    "                                        events_tst_clone.weights, \n",
    "                                        events_tst_clone.weights * reweights))\n",
    "    \n",
    "    in_CR = (SR_stat >= CR_cut) & (SR_stat < SR_cut)\n",
    "    in_SR = SR_stat >= SR_cut\n",
    "    events_tst_clone_SR = events_tst_clone[in_SR]\n",
    "    events_tst_clone_CR = events_tst_clone[in_CR]\n",
    "    \n",
    "    SR_classifier = FvTClassifier(\n",
    "        num_classes=2,\n",
    "        dim_input_jet_features=4,\n",
    "        dim_dijet_features=6,\n",
    "        dim_quadjet_features=6,\n",
    "        run_name=\"\",\n",
    "        device=device,\n",
    "        lr=0.001\n",
    "    )\n",
    "    \n",
    "    events_tst_SR_train, events_tst_SR_test = events_tst_clone_SR.split(0.9)\n",
    "    events_tst_SR_train, events_tst_SR_val = events_tst_SR_train.split(2/3)\n",
    "    events_tst_SR_train.fit_batch_size(batch_size=batch_size)\n",
    "    events_tst_SR_val.fit_batch_size(batch_size=batch_size)\n",
    "    \n",
    "    SR_classifier.fit(\n",
    "        events_tst_SR_train.to_tensor_dataset(),\n",
    "        events_tst_SR_val.to_tensor_dataset(),\n",
    "        max_epochs=10,\n",
    "        save_checkpoint=False,\n",
    "        callbacks=[], \n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    \n",
    "    SR_classifier.eval()\n",
    "    SR_classifier.to(device)\n",
    "\n",
    "    SR_classifier_scores = SR_classifier.predict(events_tst_SR_test.X_torch).detach().cpu().numpy()[:, 1]\n",
    "    \n",
    "    pi = events_tst_SR_train.total_weight_4b / events_tst_SR_train.total_weight\n",
    "    mce_score = mce_score_fn(pi=pi)\n",
    "    \n",
    "    n_samples = 1000\n",
    "    \n",
    "    auc_score_0, null_auc_scores_bootstrap, p_value_auc_bootstrap = test_via_classifier(SR_classifier_scores, \n",
    "                                                                                      events_tst_SR_test.is_4b, \n",
    "                                                                                      events_tst_SR_test.weights, \n",
    "                                                                                      auc_score, \n",
    "                                                                                      bootstrap=True, \n",
    "                                                                                      n_samples=n_samples, \n",
    "                                                                                      p_value_type=\"greater\", \n",
    "                                                                                      do_tqdm=do_tqdm)\n",
    "    auc_score_0, null_auc_scores_permutation, p_value_auc_permutation = test_via_classifier(SR_classifier_scores, \n",
    "                                                                                      events_tst_SR_test.is_4b, \n",
    "                                                                                      events_tst_SR_test.weights, \n",
    "                                                                                      auc_score, \n",
    "                                                                                      bootstrap=False, \n",
    "                                                                                      n_samples=n_samples, \n",
    "                                                                                      p_value_type=\"greater\", \n",
    "                                                                                      do_tqdm=do_tqdm)\n",
    "    mce_score_0, null_mce_scores_bootstrap, p_value_mce_bootstrap = test_via_classifier(SR_classifier_scores, \n",
    "                                                                                      events_tst_SR_test.is_4b, \n",
    "                                                                                      events_tst_SR_test.weights, \n",
    "                                                                                      mce_score, \n",
    "                                                                                      bootstrap=True, \n",
    "                                                                                      n_samples=n_samples, \n",
    "                                                                                      p_value_type=\"less\", \n",
    "                                                                                      do_tqdm=do_tqdm)\n",
    "    mce_score_0, null_mce_scores_permutation, p_value_mce_permutation = test_via_classifier(SR_classifier_scores, \n",
    "                                                                                      events_tst_SR_test.is_4b, \n",
    "                                                                                      events_tst_SR_test.weights, \n",
    "                                                                                      mce_score, \n",
    "                                                                                      bootstrap=False, \n",
    "                                                                                      n_samples=n_samples, \n",
    "                                                                                      p_value_type=\"less\", \n",
    "                                                                                      do_tqdm=do_tqdm)\n",
    "    \n",
    "        \n",
    "    \n",
    "    results = {\n",
    "        \"tstinfo_hash\": tstinfo_hash,\n",
    "        \"auc_score_0\": auc_score_0,\n",
    "        \"p_value_auc_bootstrap\": p_value_auc_bootstrap,\n",
    "        \"p_value_auc_permutation\": p_value_auc_permutation,\n",
    "        \"mce_score_0\": mce_score_0,\n",
    "        \"p_value_mce_bootstrap\": p_value_mce_bootstrap,\n",
    "        \"p_value_mce_permutation\": p_value_mce_permutation,\n",
    "        \"seed\": tstinfo.hparams[\"seed\"],\n",
    "        \"signal_ratio\": tstinfo.hparams[\"signal_ratio\"]\n",
    "    }\n",
    "    \n",
    "    df = pd.concat([df, pd.DataFrame([results])], ignore_index=True)\n",
    "    df.to_csv(df_name, sep=\"\\t\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "experiment_name = \"counting_test_v2\"\n",
    "n_3b = 100_0000\n",
    "df_debiased_binwise = pd.read_csv(f\"data/tsv/tst_results_summary_{experiment_name}_n_3b={n_3b}_debiased_binwise=True.tsv\", \n",
    "                                  sep=\"\\t\")\n",
    "df_debiased = pd.read_csv(f\"data/tsv/tst_results_summary_{experiment_name}_n_3b={n_3b}_debiased.tsv\", \n",
    "                          sep=\"\\t\")\n",
    "df_biased = pd.read_csv(f\"data/tsv/tst_results_summary_{experiment_name}_n_3b={n_3b}.tsv\", \n",
    "                              sep=\"\\t\")\n",
    "df_debiased_cheating = pd.read_csv(f\"data/tsv/tst_results_summary_{experiment_name}_n_3b={n_3b}_debiased_binwise=True_cheating=True.tsv\", \n",
    "                                  sep=\"\\t\")\n",
    "\n",
    "df_debiased[\"p_SR\"] = stats.chi2.sf(df_debiased[\"df_SR\"] * df_debiased[\"sigma_avg_SR\"]**2, df=df_debiased[\"df_SR\"])\n",
    "df_debiased[\"p_CR\"] = stats.chi2.sf(df_debiased[\"df_CR\"] * df_debiased[\"sigma_avg_CR\"]**2, df=df_debiased[\"df_CR\"])\n",
    "df_biased[\"p_SR\"] = stats.chi2.sf(df_biased[\"df_SR\"] * df_biased[\"sigma_avg_SR\"]**2, df=df_biased[\"df_SR\"])\n",
    "df_biased[\"p_CR\"] = stats.chi2.sf(df_biased[\"df_CR\"] * df_biased[\"sigma_avg_CR\"]**2, df=df_biased[\"df_CR\"])\n",
    "df_debiased_binwise[\"p_SR\"] = stats.chi2.sf(df_debiased_binwise[\"df_SR\"] * df_debiased_binwise[\"sigma_avg_SR\"]**2, df=df_debiased_binwise[\"df_SR\"])\n",
    "df_debiased_binwise[\"p_CR\"] = stats.chi2.sf(df_debiased_binwise[\"df_CR\"] * df_debiased_binwise[\"sigma_avg_CR\"]**2, df=df_debiased_binwise[\"df_CR\"])\n",
    "df_debiased_cheating[\"p_SR\"] = stats.chi2.sf(df_debiased_cheating[\"df_SR\"] * df_debiased_cheating[\"sigma_avg_SR\"]**2, df=df_debiased_cheating[\"df_SR\"])\n",
    "df_debiased_cheating[\"p_CR\"] = stats.chi2.sf(df_debiased_cheating[\"df_CR\"] * df_debiased_cheating[\"sigma_avg_CR\"]**2, df=df_debiased_cheating[\"df_CR\"])\n",
    "\n",
    "sig_level = 0.05\n",
    "\n",
    "df_debiased[\"reject_SR\"] = df_debiased[\"p_SR\"] < sig_level\n",
    "df_debiased[\"reject_CR\"] = df_debiased[\"p_CR\"] < sig_level\n",
    "df_biased[\"reject_SR\"] = df_biased[\"p_SR\"] < sig_level\n",
    "df_biased[\"reject_CR\"] = df_biased[\"p_CR\"] < sig_level\n",
    "df_debiased_binwise[\"reject_SR\"] = df_debiased_binwise[\"p_SR\"] < sig_level\n",
    "df_debiased_binwise[\"reject_CR\"] = df_debiased_binwise[\"p_CR\"] < sig_level\n",
    "df_debiased_cheating[\"reject_SR\"] = df_debiased_cheating[\"p_SR\"] < sig_level\n",
    "df_debiased_cheating[\"reject_CR\"] = df_debiased_cheating[\"p_CR\"] < sig_level\n",
    "\n",
    "print(\"biased\")\n",
    "display(df_biased[df_biased[\"nbins\"].isin([1, 2, 3, 4, 5])].groupby([\"signal_ratio\", \"reweight\", \"nbins\"]).mean()[[\"reject_SR\", \"reject_CR\"]])\n",
    "print(\"debiased\")\n",
    "display(df_debiased[df_debiased[\"nbins\"].isin([1, 2, 3, 4, 5])].groupby([\"signal_ratio\", \"reweight\", \"nbins\"]).mean()[[\"reject_SR\", \"reject_CR\"]])\n",
    "print(\"debiased_binwise\")\n",
    "display(df_debiased_binwise[df_debiased_binwise[\"nbins\"].isin([1, 2, 3, 4, 5])].groupby([\"signal_ratio\", \"reweight\", \"nbins\"]).mean()[[\"reject_SR\", \"reject_CR\"]])\n",
    "print(\"debiased_cheating\")\n",
    "display(df_debiased_cheating[df_debiased_cheating[\"nbins\"].isin([1, 2, 3, 4, 5])].groupby([\"signal_ratio\", \"reweight\", \"nbins\"]).mean()[[\"reject_SR\", \"reject_CR\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_debiased_cheating.loc[(df_debiased_cheating[\"signal_ratio\"] == 0.01) & \n",
    "                                  (df_debiased_cheating[\"nbins\"] == 5) & \n",
    "                                  (df_debiased_cheating[\"reweight\"] == \"CR\"), \"p_SR\"])\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coffea_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
